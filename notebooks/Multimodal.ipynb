{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "french-print",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "qualified-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix as sk_cmatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worthy-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the confusion matrix between rater's ratings\n",
    "    \"\"\"\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(rater_a + rater_b)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(rater_a + rater_b)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    conf_mat = [[0 for i in range(num_ratings)]\n",
    "                for j in range(num_ratings)]\n",
    "    for a, b in zip(rater_a, rater_b):\n",
    "        conf_mat[a - min_rating][b - min_rating] += 1\n",
    "    return conf_mat\n",
    "\n",
    "def histogram(ratings, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the counts of each type of rating that a rater made\n",
    "    \"\"\"\n",
    "    if min_rating is None:\n",
    "        min_rating = min(ratings)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(ratings)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    hist_ratings = [0 for x in range(num_ratings)]\n",
    "    for r in ratings:\n",
    "        hist_ratings[r - min_rating] += 1\n",
    "    return hist_ratings\n",
    "\n",
    "def quadratic_weighted_kappa(y, y_pred):\n",
    "    min_rating, max_rating =None, None\n",
    "    rater_a, rater_b = np.array(y, dtype=int), np.array(y_pred, dtype=int)\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(min(rater_a), min(rater_b))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(max(rater_a), max(rater_b))\n",
    "    conf_mat = confusion_matrix(rater_a, rater_b, min_rating, max_rating)\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    "\n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "    numerator, denominator = 0.0, 0.0\n",
    "\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i] * hist_rater_b[j] / num_scored_items)\n",
    "            d = np.square(i - j) / np.square(num_ratings - 1)\n",
    "            numerator += d * conf_mat[i][j] / num_scored_items\n",
    "            denominator += d * expected_count / num_scored_items\n",
    "\n",
    "    return (1.0 - numerator / denominator)\n",
    "\n",
    "def val_kappa(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    preds = np.argmax(preds.reshape((-1,5)), axis=1)\n",
    "    \n",
    "    return 'qwk', quadratic_weighted_kappa(labels, preds), True\n",
    "\n",
    "def val_kappa_reg(preds, train_data, cdf):\n",
    "    labels = train_data.get_label()\n",
    "    preds = getTestScore2(preds, cdf)\n",
    "    return 'qwk', quadratic_weighted_kappa(labels, preds), True\n",
    "\n",
    "def get_cdf(hist):\n",
    "    return np.cumsum(hist/np.sum(hist))\n",
    "\n",
    "def getScore(pred, cdf, valid=False):\n",
    "    num = pred.shape[0]\n",
    "    output = np.asarray([4]*num, dtype=int)\n",
    "    rank = pred.argsort()\n",
    "    output[rank[:int(num*cdf[0]-1)]] = 0\n",
    "    output[rank[int(num*cdf[0]):int(num*cdf[1]-1)]] = 1\n",
    "    output[rank[int(num*cdf[1]):int(num*cdf[2]-1)]] = 2\n",
    "    output[rank[int(num*cdf[2]):int(num*cdf[3]-1)]] = 3\n",
    "    if valid:\n",
    "        cutoff = [ pred[rank[int(num*cdf[i]-1)]] for i in range(4) ]\n",
    "        return output, cutoff\n",
    "    return output\n",
    "\n",
    "def getTestScore(pred, cutoff):\n",
    "    num = pred.shape[0]\n",
    "    output = np.asarray([4]*num, dtype=int)\n",
    "    for i in range(num):\n",
    "        if pred[i] <= cutoff[0]:\n",
    "            output[i] = 0\n",
    "        elif pred[i] <= cutoff[1]:\n",
    "            output[i] = 1\n",
    "        elif pred[i] <= cutoff[2]:\n",
    "            output[i] = 2\n",
    "        elif pred[i] <= cutoff[3]:\n",
    "            output[i] = 3\n",
    "    return output\n",
    "\n",
    "def getTestScore2(pred, cdf):\n",
    "    num = pred.shape[0]\n",
    "    rank = pred.argsort()\n",
    "    output = np.asarray([4]*num, dtype=int)\n",
    "    output[rank[:int(num*cdf[0]-1)]] = 0\n",
    "    output[rank[int(num*cdf[0]):int(num*cdf[1]-1)]] = 1\n",
    "    output[rank[int(num*cdf[1]):int(num*cdf[2]-1)]] = 2\n",
    "    output[rank[int(num*cdf[2]):int(num*cdf[3]-1)]] = 3\n",
    "    return output\n",
    "\n",
    "def rmse(actual, predicted):\n",
    "    return np.sqrt(mean_squared_error(actual, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-genome",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "latin-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afraid-zambia",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/raw/petfinder-adoption-prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "welcome-magic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "uniform-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_DIR, 'train', 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "running-banner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 24)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "twenty-pulse",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['Type', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3',\n",
    "               'Vaccinated', 'Dewormed', 'Sterilized', 'Health', 'State',\n",
    "#                 'RescuerID', 'PetID',\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "higher-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = ['Age', 'MaturitySize', 'FurLength', 'Quantity', 'Fee', 'VideoAmt', \n",
    "                   'PhotoAmt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "innocent-terror",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Age', 'Breed1', 'PhotoAmt', 'VideoAmt', 'AdoptionSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "twenty-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ignored-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how='any', subset=['AdoptionSpeed'])\n",
    "df = df[df['AdoptionSpeed'] <= 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "advised-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PhotoAmt'] = df['PhotoAmt'].fillna(0)\n",
    "df['VideoAmt'] = df['VideoAmt'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aggregate-salad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "parental-image",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>VideoAmt</th>\n",
       "      <th>PhotoAmt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14988</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14989</th>\n",
       "      <td>60.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14990</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14991</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14992</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14972 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  MaturitySize  FurLength  Quantity  Fee  VideoAmt  PhotoAmt\n",
       "0       3.0             1          1         1  100       0.0       1.0\n",
       "1       1.0             2          2         1    0       0.0       2.0\n",
       "2       1.0             2          2         1    0       0.0       7.0\n",
       "3       4.0             2          1         1  150       0.0       8.0\n",
       "4       1.0             2          1         1    0       0.0       3.0\n",
       "...     ...           ...        ...       ...  ...       ...       ...\n",
       "14988   2.0             2          2         4    0       0.0       3.0\n",
       "14989  60.0             2          2         2    0       0.0       3.0\n",
       "14990   2.0             3          2         5   30       0.0       5.0\n",
       "14991   9.0             1          1         1    0       0.0       3.0\n",
       "14992   1.0             2          1         1    0       0.0       0.0\n",
       "\n",
       "[14972 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ordinal_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "joint-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df[ordinal_features] = scaler.fit_transform(df[ordinal_features].to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "committed-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = pd.concat([pd.get_dummies(df[cat_features].astype('category'), drop_first=True), df[ordinal_features]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "together-machine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type_2</th>\n",
       "      <th>Breed1_1.0</th>\n",
       "      <th>Breed1_2.0</th>\n",
       "      <th>Breed1_3.0</th>\n",
       "      <th>Breed1_5.0</th>\n",
       "      <th>Breed1_7.0</th>\n",
       "      <th>Breed1_10.0</th>\n",
       "      <th>Breed1_11.0</th>\n",
       "      <th>Breed1_12.0</th>\n",
       "      <th>Breed1_15.0</th>\n",
       "      <th>...</th>\n",
       "      <th>State_41367</th>\n",
       "      <th>State_41401</th>\n",
       "      <th>State_41415</th>\n",
       "      <th>Age</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>VideoAmt</th>\n",
       "      <th>PhotoAmt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type_2  Breed1_1.0  Breed1_2.0  Breed1_3.0  Breed1_5.0  Breed1_7.0  \\\n",
       "0       1           0           0           0           0           0   \n",
       "1       1           0           0           0           0           0   \n",
       "2       0           0           0           0           0           0   \n",
       "3       0           0           0           0           0           0   \n",
       "4       0           0           0           0           0           0   \n",
       "\n",
       "   Breed1_10.0  Breed1_11.0  Breed1_12.0  Breed1_15.0  ...  State_41367  \\\n",
       "0            0            0            0            0  ...            0   \n",
       "1            0            0            0            0  ...            0   \n",
       "2            0            0            0            0  ...            0   \n",
       "3            0            0            0            0  ...            0   \n",
       "4            0            0            0            0  ...            0   \n",
       "\n",
       "   State_41401  State_41415       Age  MaturitySize  FurLength  Quantity  \\\n",
       "0            0            0  0.011765      0.142857        0.0       0.0   \n",
       "1            1            0  0.003922      0.285714        0.5       0.0   \n",
       "2            0            0  0.003922      0.285714        0.5       0.0   \n",
       "3            1            0  0.015686      0.285714        0.0       0.0   \n",
       "4            0            0  0.003922      0.285714        0.0       0.0   \n",
       "\n",
       "        Fee  VideoAmt  PhotoAmt  \n",
       "0  0.033333       0.0  0.033333  \n",
       "1  0.000000       0.0  0.066667  \n",
       "2  0.000000       0.0  0.233333  \n",
       "3  0.050000       0.0  0.266667  \n",
       "4  0.000000       0.0  0.100000  \n",
       "\n",
       "[5 rows x 366 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "tamil-trouble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14972, 366)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "developmental-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df['Age'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-minnesota",
   "metadata": {},
   "source": [
    "## Text processsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fresh-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = df['Description'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "parliamentary-cookbook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Nibble is a 3+ month old ball of cuteness. He ...\n",
       "1        I just found it alone yesterday near my apartm...\n",
       "2        Their pregnant mother was dumped by her irresp...\n",
       "3        Good guard dog, very alert, active, obedience ...\n",
       "4        This handsome yet cute boy is up for adoption....\n",
       "                               ...                        \n",
       "14988    I have 4 kittens that need to be adopt urgentl...\n",
       "14989    Serato(female cat- 3 color) is 4 years old and...\n",
       "14990    Mix breed, good temperament kittens. Love huma...\n",
       "14991    she is very shy..adventures and independent..s...\n",
       "14992    Fili just loves laying around and also loves b...\n",
       "Name: Description, Length: 14972, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "optional-thirty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect_langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "separated-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detecting_languages(x):\n",
    "    if len(x) == 0:\n",
    "        return ''\n",
    "    else:\n",
    "        try:\n",
    "            lang = detect_langs(x)[0].lang\n",
    "            return lang\n",
    "        except:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "accomplished-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = map(lambda x: detecting_languages(x), descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dense-grace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en       14100\n",
       "id         458\n",
       "da         102\n",
       "de          64\n",
       "zh-cn       32\n",
       "ro          23\n",
       "tl          23\n",
       "no          22\n",
       "es          15\n",
       "af          13\n",
       "nl          11\n",
       "so          11\n",
       "ko           9\n",
       "fr           9\n",
       "cy           8\n",
       "-            8\n",
       "ca           8\n",
       "fi           8\n",
       "it           5\n",
       "sl           5\n",
       "zh-tw        5\n",
       "hr           5\n",
       "sv           4\n",
       "0            4\n",
       "sk           4\n",
       "vi           3\n",
       "pt           2\n",
       "et           2\n",
       ".            2\n",
       ":)           2\n",
       "sw           1\n",
       "tr           1\n",
       "hu           1\n",
       "---          1\n",
       "..           1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-range",
   "metadata": {},
   "source": [
    "## Dataset Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "european-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "personalized-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "super-turtle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train images files: 58311\n",
      "num of train metadata files: 58311\n",
      "num of train sentiment files: 14442\n",
      "num of test images files: 14465\n",
      "num of test metadata files: 14465\n",
      "num of test sentiment files: 3865\n"
     ]
    }
   ],
   "source": [
    "train_image_files = sorted(glob.glob(os.path.join(DATA_DIR, 'train_images/*.jpg')))\n",
    "train_metadata_files = sorted(glob.glob(os.path.join(DATA_DIR, 'train_metadata/*.json')))\n",
    "train_sentiment_files = sorted(glob.glob(os.path.join(DATA_DIR,'train_sentiment/*.json')))\n",
    "\n",
    "print('num of train images files: {}'.format(len(train_image_files)))\n",
    "print('num of train metadata files: {}'.format(len(train_metadata_files)))\n",
    "print('num of train sentiment files: {}'.format(len(train_sentiment_files)))\n",
    "\n",
    "test_image_files = sorted(glob.glob(os.path.join(DATA_DIR,'test_images/*.jpg')))\n",
    "test_metadata_files = sorted(glob.glob(os.path.join(DATA_DIR,'test_metadata/*.json')))\n",
    "test_sentiment_files = sorted(glob.glob(os.path.join(DATA_DIR,'test_sentiment/*.json')))\n",
    "\n",
    "print('num of test images files: {}'.format(len(test_image_files)))\n",
    "print('num of test metadata files: {}'.format(len(test_metadata_files)))\n",
    "print('num of test sentiment files: {}'.format(len(test_sentiment_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "parallel-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df = pd.DataFrame(train_image_files, columns=['path'])\n",
    "\n",
    "def get_petid(path):\n",
    "    basename = os.path.basename(path)\n",
    "    return basename.split('-')[0]\n",
    "def get_picid(path):\n",
    "    basename = os.path.splitext(os.path.basename(path))[0]\n",
    "    return basename.split('-')[1]\n",
    "\n",
    "\n",
    "image_df['PetID'] = image_df['path'].apply(get_petid)\n",
    "# image_df['PicID'] = image_df['path'].apply(get_picid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "blocked-jurisdiction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>PetID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/raw/petfinder-adoption-prediction/trai...</td>\n",
       "      <td>0008c5398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/raw/petfinder-adoption-prediction/trai...</td>\n",
       "      <td>0008c5398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/raw/petfinder-adoption-prediction/trai...</td>\n",
       "      <td>0008c5398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/raw/petfinder-adoption-prediction/trai...</td>\n",
       "      <td>0008c5398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/raw/petfinder-adoption-prediction/trai...</td>\n",
       "      <td>0008c5398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58306</th>\n",
       "      <td>../data/raw/petfinder-adoption-prediction/trai...</td>\n",
       "      <td>fffa39a6a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58307</th>\n",
       "      <td>../data/raw/petfinder-adoption-prediction/trai...</td>\n",
       "      <td>fffa39a6a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58308</th>\n",
       "      <td>../data/raw/petfinder-adoption-prediction/trai...</td>\n",
       "      <td>fffd78a11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58309</th>\n",
       "      <td>../data/raw/petfinder-adoption-prediction/trai...</td>\n",
       "      <td>fffd78a11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58310</th>\n",
       "      <td>../data/raw/petfinder-adoption-prediction/trai...</td>\n",
       "      <td>fffd9b5a8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58311 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    path      PetID\n",
       "0      ../data/raw/petfinder-adoption-prediction/trai...  0008c5398\n",
       "1      ../data/raw/petfinder-adoption-prediction/trai...  0008c5398\n",
       "2      ../data/raw/petfinder-adoption-prediction/trai...  0008c5398\n",
       "3      ../data/raw/petfinder-adoption-prediction/trai...  0008c5398\n",
       "4      ../data/raw/petfinder-adoption-prediction/trai...  0008c5398\n",
       "...                                                  ...        ...\n",
       "58306  ../data/raw/petfinder-adoption-prediction/trai...  fffa39a6a\n",
       "58307  ../data/raw/petfinder-adoption-prediction/trai...  fffa39a6a\n",
       "58308  ../data/raw/petfinder-adoption-prediction/trai...  fffd78a11\n",
       "58309  ../data/raw/petfinder-adoption-prediction/trai...  fffd78a11\n",
       "58310  ../data/raw/petfinder-adoption-prediction/trai...  fffd9b5a8\n",
       "\n",
       "[58311 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "elder-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(image_df.drop_duplicates(subset=['PetID']), on='PetID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "thick-pocket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14972, 25)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "loving-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "entire-mouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "seventh-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def img_to_torch(image):\n",
    "    return torch.from_numpy(np.transpose(image, (2, 0, 1))).type(torch.FloatTensor)\n",
    "\n",
    "def pad_to_square(image):\n",
    "    h, w = image.shape[0:2]\n",
    "    new_size = max(h, w)\n",
    "    delta_top = (new_size-h)//2\n",
    "    delta_bottom = new_size-h-delta_top\n",
    "    delta_left = (new_size-w)//2\n",
    "    delta_right = new_size-delta_left-w\n",
    "    new_im = cv2.copyMakeBorder(image, delta_top, delta_bottom, delta_left, delta_right, \n",
    "                                cv2.BORDER_CONSTANT,  value=[0,0,0])\n",
    "    return new_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "concerned-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "import nltk\n",
    "isascii = lambda s: len(s) == len(s.encode())\n",
    "tknzr = TweetTokenizer()\n",
    "import jieba\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "lc = LancasterStemmer()\n",
    "from nltk.stem import SnowballStemmer\n",
    "sb = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "offensive-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_emb_matrix(word_dict, emb_dict):\n",
    "    embed_size = 300\n",
    "    nb_words = len(word_dict)+1000\n",
    "    nb_oov = 0\n",
    "    embedding_matrix = np.zeros((nb_words, embed_size), dtype=np.float32)\n",
    "    unknown_vector = np.zeros((embed_size,), dtype=np.float32) - 1.\n",
    "    for key in tqdm(word_dict):\n",
    "        word = key\n",
    "        embedding_vector = emb_dict.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = key.lower()\n",
    "        embedding_vector = emb_dict.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = key.upper()\n",
    "        embedding_vector = emb_dict.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = key.capitalize()\n",
    "        embedding_vector = emb_dict.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = ps.stem(key)\n",
    "        embedding_vector = emb_dict.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = lc.stem(key)\n",
    "        embedding_vector = emb_dict.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = sb.stem(key)\n",
    "        embedding_vector = emb_dict.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        nb_oov+=1\n",
    "        embedding_matrix[word_dict[key]] = unknown_vector                    \n",
    "    return embedding_matrix, nb_words, nb_oov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "stuck-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(text):\n",
    "    init_doc = tknzr.tokenize(text)\n",
    "    retval = []\n",
    "    for t in init_doc:\n",
    "        if isascii(t): \n",
    "            retval.append(t)\n",
    "        else:\n",
    "            for w in t:\n",
    "                retval.append(w)\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "changed-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Description'] = df['Description'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "academic-instrument",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def text_cleaning(text):\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r\"[^A-Za-z(),!?\\'\\`]\", \" \", text)\n",
    "    text = text.lower()\n",
    "    text = custom_tokenizer(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = [i for i in text if not i in stop_words]\n",
    "    text = [lemmatizer.lemmatize(token) for token in text]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "short-grave",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "indirect-analyst",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14972/14972 [00:07<00:00, 2083.95it/s]\n"
     ]
    }
   ],
   "source": [
    "texts = df['Description'].progress_apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "adjustable-floor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14972/14972 [00:31<00:00, 471.62it/s]\n"
     ]
    }
   ],
   "source": [
    "english_desc, chinese_desc = [], []\n",
    "tokens = set()\n",
    "word_dict = {}\n",
    "pos_count, word_count = 1, 1 # starts from 1, 0 for padding token\n",
    "pos_dict = {}\n",
    "eng_sequences = []\n",
    "pos_sequences = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    e_d, c_d, eng_seq, pos_seq = [], [], [], []\n",
    "    doc = custom_tokenizer(df['Description'].iloc[i])\n",
    "    for token in doc:\n",
    "        if not isascii(token):\n",
    "            c_d.append(token)\n",
    "        else:\n",
    "            e_d.append(token)\n",
    "            if token not in word_dict:\n",
    "                word_dict[token] = word_count\n",
    "                word_count +=1\n",
    "    english_desc.append(' '.join(e_d))\n",
    "    chinese_desc.append(' '.join(c_d))\n",
    "    pos_seq = nltk.pos_tag(e_d)\n",
    "    for t in pos_seq:\n",
    "        if t[1] not in pos_dict:\n",
    "            pos_dict[t[1]] = pos_count\n",
    "            pos_count += 1\n",
    "    pos_seq = [pos_dict[t[1]] for t in pos_seq]\n",
    "    eng_seq = [word_dict[t] for t in e_d]\n",
    "    if len(eng_seq)==0:\n",
    "        eng_seq.append(0)\n",
    "        pos_seq.append(0)\n",
    "    eng_sequences.append(eng_seq)\n",
    "    pos_sequences.append(pos_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "north-accountability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14972\n"
     ]
    }
   ],
   "source": [
    "print(len(eng_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "understood-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "lined-america",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28597/28597 [00:00<00:00, 131217.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29597 4054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# build embedding\n",
    "def load_glove():\n",
    "    EMBEDDING_FILE = './.vector_cache/glove.840B.300d.txt'\n",
    "\n",
    "    def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in (open(EMBEDDING_FILE)))\n",
    "    return embeddings_index\n",
    "\n",
    "glove_emb = load_glove()\n",
    "\n",
    "embedding_matrix, vocab_size, nb_oov = build_emb_matrix(word_dict, glove_emb)\n",
    "print(vocab_size, nb_oov)\n",
    "del glove_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "oriented-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "rapid-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "exciting-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetDataset(data.Dataset):\n",
    "    def __init__(self, df, processed_df, tokenized_texts=eng_sequences, image_size=512, mode='train', max_len_text=200):\n",
    "        self.df = df\n",
    "        self.processed_df = processed_df\n",
    "        self.path = df['path'].tolist()\n",
    "        self.image_size = image_size\n",
    "        self.max_len_text = max_len_text\n",
    "        self.tokenized_texts = tokenized_texts\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx not in range(0, len(self.df)):\n",
    "            return self.__getitem__(np.random.randint(0, self.__len__()))\n",
    "        sample = {}\n",
    "        if os.path.exists(str(self.path[idx])):\n",
    "            image = cv2.imread(self.path[idx]) / 255.0\n",
    "            image = pad_to_square(image)\n",
    "            image = cv2.resize(image, (self.image_size, self.image_size)) \n",
    "        else:\n",
    "            image = np.zeros((self.image_size, self.image_size, 3), dtype=np.uint8)\n",
    "        \n",
    "        image = img_to_torch(image)\n",
    "\n",
    "        row = self.processed_df.iloc[idx].values.astype('float')\n",
    "        \n",
    "        sequence = self.tokenized_texts[idx][:self.max_len_text]\n",
    "        sequence = torch.tensor(sequence)\n",
    "        label = self.df['AdoptionSpeed'].iloc[idx]\n",
    "        if self.mode != 'test':\n",
    "            return image, row, sequence, label\n",
    "        else:\n",
    "            return image, row, sequence\n",
    "        \n",
    "def nn_collate(batch):\n",
    "    has_label = len(batch[0]) == 4\n",
    "    if has_label:\n",
    "#         print('padding sequences')\n",
    "        images, rows, sequences, labels = zip(*batch)\n",
    "        sequences = nn.utils.rnn.pad_sequence(sequences, batch_first=True).type(torch.LongTensor)\n",
    "        rows = torch.LongTensor(rows)\n",
    "        return images, rows, sequences, labels\n",
    "        \n",
    "\n",
    "    else:\n",
    "        images, rows, sequences = zip(*batch)\n",
    "        sequences = nn.utils.rnn.pad_sequence(sequences, batch_first=True).type(torch.LongTensor)\n",
    "        rows = torch.LongTensor(rows)\n",
    "\n",
    "        return images, rows, sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "future-length",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14972, 366) (14972, 25)\n"
     ]
    }
   ],
   "source": [
    "print(processed_df.shape, df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "overall-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.loc[processed_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-booth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-romantic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-sampling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "deluxe-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "portable-tension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "pleasant-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "undefined-accent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.vgg19_bn(pretrained=True)\n",
    "in_features = model.classifier[-1].in_features\n",
    "in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "healthy-decade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "in_features = model.fc.in_features\n",
    "in_features.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "supposed-elephant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "social-feedback",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1024, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.models.densenet121(pretrained=True).classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "intellectual-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self, emb_size):\n",
    "        super().__init__()\n",
    "        model = torchvision.models.resnet18(pretrained=True)\n",
    "#         in_features = model.classifier[-1].in_features\n",
    "        self.feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
    "\n",
    "        in_features = model.fc.in_features\n",
    "#         print(in_features)\n",
    "        self.fc = nn.Linear(in_features, emb_size)\n",
    "        \n",
    "    def forward(self, image):\n",
    "        with torch.no_grad():\n",
    "            img_feature = self.feature_extractor(image)\n",
    "        \n",
    "#         print(img_feature.shape)\n",
    "        img_feature = img_feature.view(img_feature.size(0), -1)\n",
    "        img_feature = self.fc(img_feature)\n",
    "        \n",
    "        l2_norm = img_feature.norm(p=2, dim=1, keepdim=True).detach()\n",
    "        img_feature = img_feature.div(l2_norm)\n",
    "        return img_feature\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "awful-strand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn([1,3,512,512])\n",
    "ImageEncoder(128)(x).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "hidden-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularAutoencoder(nn.Module):\n",
    "    def __init__(self, input_shape, latent_dim):\n",
    "        super().__init__()\n",
    "        encoder = nn.Sequential(nn.Linear(input_shape, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, latent_dim),\n",
    "                            nn.Tanh())\n",
    "        decoder = nn.Sequential(nn.Linear(latent_dim, 64),\n",
    "                               nn.Tanh(),\n",
    "                               nn.Linear(64, input_shape),\n",
    "                               nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = encoder(x)\n",
    "        x = decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def get_latent_feature(self, x):\n",
    "        return encoder(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "liked-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularFeedforwardNN(nn.Module):\n",
    "    def __init__(self, input_size, latent_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, latent_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "answering-times",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = torch.randn((4, 366))\n",
    "TabularFeedforwardNN(366, 128)(row).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "prescribed-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEncoder(nn.Module):\n",
    "    def turn_on_embedding(self):\n",
    "        self.embedding.weight.requires_grad = True\n",
    "\n",
    "    def __init__(self, vocab_size, word_emb_size, embed_size, num_layers, hidden_size, init_embedding=None):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, word_emb_size)\n",
    "        \n",
    "        if init_embedding is not None:\n",
    "            self.embedding.weight.data.copy_(torch.from_numpy(init_embedding))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.lstm = nn.LSTM(word_emb_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(2*num_layers*hidden_size, embed_size)\n",
    "        # 2 for hidden and cell states\n",
    "        \n",
    "    def forward(self, text):\n",
    "        text_vec = self.embedding(text) # shape: (BATCH_SIZE, MAX_LEN, word_emb_size)\n",
    "#         print(text_vec.shape)\n",
    "        text_vec = self.tanh(text_vec)\n",
    "        text_vec = text_vec.transpose(0, 1) # shape: (MAX_LEN, BATCH_SIZE, word_emb_size)\n",
    "        output, (hidden, cell) = self.lstm(text_vec)\n",
    "#         print(hidden.shape, cell.shape)\n",
    "        text_vec = torch.cat((hidden, cell), 2) \n",
    "#         print(text_vec.shape)\n",
    "        text_vec = text_vec.reshape(text_vec.size()[1], -1) # shape (BATCH_SIZE, 2*num_layers*hidden_size)\n",
    "#         print(text_vec.shape)\n",
    "        \n",
    "        text_vec = self.tanh(text_vec)\n",
    "#         print(text_vec.shape)\n",
    "\n",
    "        text_vec = self.fc(text_vec)\n",
    "        return text_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "appreciated-night",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = torch.randint(0, 255, (4, 200))\n",
    "TextEncoder(vocab_size, 300, 128, 2, 256, init_embedding=embedding_matrix)(sequence).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "laden-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = 366\n",
    "latent_dim = 128\n",
    "tabular_autoencoder = TabularAutoencoder(input_shape, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "filled-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multimodal(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        img_emb_size = kwargs.get('emb_size', 128)\n",
    "\n",
    "        vocab_size = kwargs.get('vocab_size')\n",
    "#         print(vocab_size)\n",
    "        word_emb_size = kwargs.get('word_emb_size', 300)\n",
    "        num_layers = kwargs.get('num_layers', 2)\n",
    "        hidden_size = kwargs.get('hidden_size', 256)\n",
    "\n",
    "        # Use the same emb size for all modals\n",
    "        embed_size = img_emb_size\n",
    "        \n",
    "        n_classes = kwargs.get('n_classes', 5)\n",
    "        \n",
    "        self.img_encoder = ImageEncoder(img_emb_size)\n",
    "        self.text_encoder = TextEncoder(vocab_size, word_emb_size, embed_size, num_layers, hidden_size, \n",
    "                                       init_embedding=embedding_matrix)\n",
    "#         self.tabular_encoder = tabular_autoencoder\n",
    "        self.tabular_encoder = TabularFeedforwardNN(input_size=366, latent_dim=embed_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc1 = nn.Linear(embed_size, 64)\n",
    "        self.fc2 = nn.Linear(64, n_classes)\n",
    "        \n",
    "    def forward(self, img, row, text):\n",
    "        img_feature = self.img_encoder(img)\n",
    "        text_feature = self.text_encoder(text)\n",
    "        tabular_latent_feature = self.tabular_encoder(row)\n",
    "#         print(img_feature.shape)\n",
    "#         print(tabular_latent_feature.shape)\n",
    "#         print(text_feature.shape)\n",
    "        combined_feature = img_feature * text_feature * tabular_latent_feature\n",
    "        combined_feature = self.tanh(combined_feature)\n",
    "        combined_feature = self.fc1(combined_feature)\n",
    "        combined_feature = self.dropout(combined_feature)\n",
    "        combined_feature = self.fc2(combined_feature)\n",
    "#         output = F.softmax(conbined_feature, dim=1)\n",
    "        return combined_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "complex-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "n_splits = 5\n",
    "# kfold = GroupKFold(n_splits=n_splits)\n",
    "split_index = []\n",
    "# for train_idx, valid_idx in kfold.split(train, train['AdoptionSpeed'], train['RescuerID']):\n",
    "#     split_index.append((train_idx, valid_idx))\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "for train_idx, valid_idx in kfold.split(df, df['AdoptionSpeed']):\n",
    "    split_index.append((train_idx, valid_idx))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "careful-synthesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "polish-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "humanitarian-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "elder-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "hired-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "moderate-creativity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #0\n",
      "Epoch #0\n",
      "step 0 loss =  tensor(1.6222, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.5105, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.5377, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.4314, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.546712815691299\n",
      "qwk 0.01893909416664774\n",
      "Epoch #1\n",
      "step 0 loss =  tensor(1.3347, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3830, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.3997, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.4030, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.5736774663019668\n",
      "qwk -0.0013462267170447628\n",
      "Epoch #2\n",
      "step 0 loss =  tensor(1.2859, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3249, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.3991, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.2841, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.7283842706349468\n",
      "qwk 0.015558207352699083\n",
      "Epoch #3\n",
      "step 0 loss =  tensor(1.4247, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3039, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.2851, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3400, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6439294916822633\n",
      "qwk 0.02038804565834018\n",
      "Epoch #4\n",
      "step 0 loss =  tensor(1.3383, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.4390, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.3204, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.4908, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.663915369621335\n",
      "qwk -0.007866508429660302\n",
      "Epoch #5\n",
      "step 0 loss =  tensor(1.3036, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.2841, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.4382, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3683, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6051877500326117\n",
      "qwk 0.01918058608192985\n",
      "Epoch #6\n",
      "step 0 loss =  tensor(1.5353, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3422, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.4357, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.2944, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6593942616285848\n",
      "qwk -0.005210097361557864\n",
      "Epoch #7\n",
      "step 0 loss =  tensor(1.3320, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.4442, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.3910, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.2638, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.7065131052227998\n",
      "qwk -0.039501949331609776\n",
      "Epoch #8\n",
      "step 0 loss =  tensor(1.2325, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.2673, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.2997, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3975, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.656474120187641\n",
      "qwk -0.0023121943781729826\n",
      "Epoch #9\n",
      "step 0 loss =  tensor(1.3251, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3590, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.2805, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3768, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.738592680161895\n",
      "qwk -0.01559424971868606\n",
      "Fold #1\n",
      "Epoch #0\n",
      "step 0 loss =  tensor(1.6324, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.5158, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.4878, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.4926, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6621084021710535\n",
      "qwk -0.009782319028407427\n",
      "Epoch #1\n",
      "step 0 loss =  tensor(1.4336, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.4335, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.3428, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3928, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6742177302690489\n",
      "qwk -0.01412598774450502\n",
      "Epoch #2\n",
      "step 0 loss =  tensor(1.4384, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3102, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.3698, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.5546, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.694240464412324\n",
      "qwk 0.010488134980049302\n",
      "Epoch #3\n",
      "step 0 loss =  tensor(1.4190, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3255, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.3543, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.4206, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6393532663481893\n",
      "qwk 0.00035290797582088196\n",
      "Epoch #4\n",
      "step 0 loss =  tensor(1.4912, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3591, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.4067, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.4182, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.7372478378410698\n",
      "qwk -0.00809311452770256\n",
      "Epoch #5\n",
      "step 0 loss =  tensor(1.2726, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.4248, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.2837, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3716, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6781021158395901\n",
      "qwk 0.0008355378331650343\n",
      "Epoch #6\n",
      "step 0 loss =  tensor(1.3528, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.1701, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.3015, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.2623, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.7102265321643402\n",
      "qwk -0.019193601246619396\n",
      "Epoch #7\n",
      "step 0 loss =  tensor(1.3114, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3788, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.3311, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.2788, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6854478804151711\n",
      "qwk -0.02353726996271721\n",
      "Epoch #8\n",
      "step 0 loss =  tensor(1.2889, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3235, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.2639, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.2157, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6866360708203536\n",
      "qwk -0.021124120675996227\n",
      "Epoch #9\n",
      "step 0 loss =  tensor(1.2793, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.1478, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.2523, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3089, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6576830784705943\n",
      "qwk 0.00011159304714902785\n",
      "Fold #2\n",
      "Epoch #0\n",
      "step 0 loss =  tensor(1.6333, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.4833, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.4023, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3805, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.7105121172931845\n",
      "qwk 0.03312513922673477\n",
      "Epoch #1\n",
      "step 0 loss =  tensor(1.4273, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3409, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.4238, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3645, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6606772809297192\n",
      "qwk -0.010565873081332056\n",
      "Epoch #2\n",
      "step 0 loss =  tensor(1.3380, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.4264, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.3130, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.4776, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.631663154360788\n",
      "qwk -0.0018759479813847957\n",
      "Epoch #3\n",
      "step 0 loss =  tensor(1.5865, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.2981, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.4781, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3066, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6412558529623282\n",
      "qwk -0.03518732753118137\n",
      "Epoch #4\n",
      "step 0 loss =  tensor(1.3854, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3656, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.3260, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3300, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.639321429585729\n",
      "qwk 0.013814194560186066\n",
      "Epoch #5\n",
      "step 0 loss =  tensor(1.2242, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.2602, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.3425, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.2452, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6180965585977531\n",
      "qwk 0.009710618818544181\n",
      "Epoch #6\n",
      "step 0 loss =  tensor(1.4722, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.4198, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.2529, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3482, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.7237389260278195\n",
      "qwk -0.026738789239566296\n",
      "Epoch #7\n",
      "step 0 loss =  tensor(1.3687, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.2469, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.2105, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.1424, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6581613305091853\n",
      "qwk 0.00874507158521698\n",
      "Epoch #8\n",
      "step 0 loss =  tensor(1.2425, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.4532, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.2637, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3158, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6212928527450114\n",
      "qwk 0.0007793069102656203\n",
      "Epoch #9\n",
      "step 0 loss =  tensor(1.2660, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.1751, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.3889, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.2863, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.5789192417422393\n",
      "qwk 0.05074637623496048\n",
      "Fold #3\n",
      "Epoch #0\n",
      "step 0 loss =  tensor(1.6006, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.4963, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.4011, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3705, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6541278501239796\n",
      "qwk 0.0029517881852525463\n",
      "Epoch #1\n",
      "step 0 loss =  tensor(1.4865, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3488, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.2548, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.4700, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6314584415873383\n",
      "qwk 0.025642148168447232\n",
      "Epoch #2\n",
      "step 0 loss =  tensor(1.5414, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3387, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.3956, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3760, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.7154841216237142\n",
      "qwk -0.00477258968136729\n",
      "Epoch #3\n",
      "step 0 loss =  tensor(1.4238, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3349, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.3970, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.4556, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6661989991823964\n",
      "qwk 0.00681397711856202\n",
      "Epoch #4\n",
      "step 0 loss =  tensor(1.4038, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3068, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.2522, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3773, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6693031918416095\n",
      "qwk 0.0012620805269291102\n",
      "Epoch #5\n",
      "step 0 loss =  tensor(1.3501, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3229, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.3927, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3525, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.645219385670892\n",
      "qwk -0.023359373922920312\n",
      "Epoch #6\n",
      "step 0 loss =  tensor(1.3734, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3209, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.3798, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3249, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6982642716627308\n",
      "qwk 0.00922784520188058\n",
      "Epoch #7\n",
      "step 0 loss =  tensor(1.1484, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3029, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.4728, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.4486, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6467412811450948\n",
      "qwk 0.008020911160221411\n",
      "Epoch #8\n",
      "step 0 loss =  tensor(1.2873, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3009, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.4128, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3798, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6115813317290428\n",
      "qwk 0.00681397711856202\n",
      "Epoch #9\n",
      "step 0 loss =  tensor(1.1937, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3364, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.2772, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.2973, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6976741525952834\n",
      "qwk 0.015021128601845235\n",
      "Fold #4\n",
      "Epoch #0\n",
      "step 0 loss =  tensor(1.6162, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.4254, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.4786, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3184, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.5766965287866197\n",
      "qwk 0.008375865385872205\n",
      "Epoch #1\n",
      "step 0 loss =  tensor(1.4332, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3158, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.4562, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3555, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.620365545899446\n",
      "qwk 0.017555333623469394\n",
      "Epoch #2\n",
      "step 0 loss =  tensor(1.4775, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.2986, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.3795, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.2926, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6330954252592442\n",
      "qwk -0.021578188863129455\n",
      "Epoch #3\n",
      "step 0 loss =  tensor(1.4209, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.2492, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.2542, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3521, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6377926393346984\n",
      "qwk -0.02012879914140364\n",
      "Epoch #4\n",
      "step 0 loss =  tensor(1.3007, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3426, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.4057, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3170, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.639525160578821\n",
      "qwk 0.01103307987570279\n",
      "Epoch #5\n",
      "step 0 loss =  tensor(1.3149, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.2671, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.4463, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3740, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6621850232258157\n",
      "qwk -0.0107077659501853\n",
      "Epoch #6\n",
      "step 0 loss =  tensor(1.2131, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3777, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.2257, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.4742, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.7599796561646843\n",
      "qwk -0.02544322812106503\n",
      "Epoch #7\n",
      "step 0 loss =  tensor(1.2990, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3467, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.3431, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3284, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6107521156557616\n",
      "qwk 0.04291965375367257\n",
      "Epoch #8\n",
      "step 0 loss =  tensor(1.3204, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.2921, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.3678, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.3659, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.6596713584430118\n",
      "qwk -0.009983071089322504\n",
      "Epoch #9\n",
      "step 0 loss =  tensor(1.3735, grad_fn=<NllLossBackward>)\n",
      "step 50 loss =  tensor(1.3115, grad_fn=<NllLossBackward>)\n",
      "step 100 loss =  tensor(1.4345, grad_fn=<NllLossBackward>)\n",
      "step 150 loss =  tensor(1.1868, grad_fn=<NllLossBackward>)\n",
      "val_loss 1.5438372756654553\n",
      "qwk 0.014414989226396613\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(split_index):\n",
    "    print(f'Fold #{fold}')\n",
    "    y_train = df['AdoptionSpeed'].iloc[train_idx].values\n",
    "    y_val = df['AdoptionSpeed'].iloc[val_idx].values\n",
    "    \n",
    "    hist = histogram(y_train.astype(int), int(np.min(df['AdoptionSpeed'])), int(np.max(df['AdoptionSpeed'])))\n",
    "    \n",
    "    train_cdf = get_cdf(hist)\n",
    "    \n",
    "    training_set = PetDataset(df.iloc[train_idx], processed_df.iloc[train_idx])\n",
    "    validation_set = PetDataset(df.iloc[val_idx], processed_df.iloc[val_idx])\n",
    "\n",
    "    training_loader = DataLoader(training_set, batch_size=batch_size, shuffle=True, pin_memory=True, collate_fn=nn_collate)\n",
    "    validating_loader = DataLoader(validation_set, batch_size=batch_size, shuffle=True, pin_memory=True, collate_fn=nn_collate)\n",
    "\n",
    "    model = Multimodal(vocab_size=vocab_size).cuda()\n",
    "\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "#     scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=7, eta_min=0.0003)\n",
    "\n",
    "    sparse_cse_loss = nn.CrossEntropyLoss(reduction='mean')\n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    iteration = 0\n",
    "    min_val_loss = 100\n",
    "    since = time.time()\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f'Epoch #{epoch}')\n",
    "        model.train()\n",
    "        for step, (image, row, sequence, y) in enumerate(training_loader):\n",
    "            iteration += 1\n",
    "            image = torch.stack(image).cuda()\n",
    "            row = row.type(torch.FloatTensor).cuda()\n",
    "#             print(row.shape)\n",
    "            sequence = sequence.cuda()\n",
    "            pred = model(image, row, sequence)            \n",
    "            loss = sparse_cse_loss(pred.type(torch.FloatTensor), torch.LongTensor(y))\n",
    "            optimizer.zero_grad()\n",
    "            if step%50 ==0:\n",
    "                print('step', step, 'loss = ', loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "#             scheduler.step()\n",
    "        \n",
    "        model.eval()\n",
    "        val_predicts = []\n",
    "        with torch.no_grad():\n",
    "            for image, row, sequence, y in validating_loader:\n",
    "                image = torch.stack(image).cuda()\n",
    "                row = row.type(torch.FloatTensor).cuda()\n",
    "                sequence = sequence.cuda()\n",
    "                y = torch.FloatTensor(y).cuda()#.view(-1, 1)\n",
    "                \n",
    "                val_predicts.append(model(image, row, sequence).cpu().numpy())\n",
    "        val_predicts_ = np.concatenate(val_predicts)\n",
    "        val_predicts_ = val_predicts_.argmax(axis=1)\n",
    "\n",
    "        pred_test_y_k = getTestScore2(val_predicts_, train_cdf)\n",
    "        qwk = quadratic_weighted_kappa(y_val, pred_test_y_k)\n",
    "        val_loss = rmse(y_val, val_predicts_)\n",
    "\n",
    "        print('val_loss', val_loss)\n",
    "        print('qwk', qwk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-medication",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "prerequisite-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-belle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
