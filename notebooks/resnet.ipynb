{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "petfinder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBDLO2K_lPgq",
        "outputId": "baa16084-9169-4a4d-c4ea-dc7870f23714"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6ON0ynZlcHX"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/petfinder ./"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6WFtmnonZTP",
        "outputId": "7d29990d-ff80-4a31-82a5-5e233032a824"
      },
      "source": [
        "%cd petfinder\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/petfinder\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TLFzWGzloB1"
      },
      "source": [
        "!unzip -qq petfinder-adoption-prediction.zip"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "2l4_okFGhqK_"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.applications.resnet import preprocess_input, ResNet101\n",
        "from keras.utils import to_categorical\n",
        "from dataset import My_Custom_Generator"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "IvB-MPxehqLE",
        "outputId": "0517cea5-019a-4fdd-f93f-eb254a4a5462"
      },
      "source": [
        "path = 'train/train.csv'\n",
        "df_pet = pd.read_csv(path)\n",
        "df = df_pet[['PetID','PhotoAmt','AdoptionSpeed']]\n",
        "df = df[df['PhotoAmt']>0]\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PetID</th>\n",
              "      <th>PhotoAmt</th>\n",
              "      <th>AdoptionSpeed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86e1089a3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6296e909a</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3422e4906</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5842f1ff5</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850a43f90</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       PetID  PhotoAmt  AdoptionSpeed\n",
              "0  86e1089a3       1.0              2\n",
              "1  6296e909a       2.0              0\n",
              "2  3422e4906       7.0              3\n",
              "3  5842f1ff5       8.0              2\n",
              "4  850a43f90       3.0              2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "vGCVdRsshqLI",
        "outputId": "5fb08a5d-e356-4849-c69f-14d5ad1c6926"
      },
      "source": [
        "df['AdoptionSpeed'].value_counts().plot(kind='bar')\n",
        "plt.title(\"Distrubition of label\")\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5NwIBBi4hqLJ"
      },
      "source": [
        "def resize_to_square(im):\n",
        "    old_size = im.shape[:2] # old_size is in (height, width) format\n",
        "    ratio = float(img_size)/max(old_size)\n",
        "    new_size = tuple([int(x*ratio) for x in old_size])\n",
        "    # new_size should be in (width, height) format\n",
        "    im = cv2.resize(im, (new_size[1], new_size[0]))\n",
        "    delta_w = img_size - new_size[1]\n",
        "    delta_h = img_size - new_size[0]\n",
        "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
        "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
        "    color = [0, 0, 0]\n",
        "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
        "    return new_im\n",
        "\n",
        "def load_image(path, pet_id):\n",
        "    image = cv2.imread(f'{path}{pet_id}-1.jpg')\n",
        "    new_image = resize_to_square(image)\n",
        "    new_image = preprocess_input(new_image)\n",
        "    return new_image\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Lgpi-vZghqLL"
      },
      "source": [
        "img_size = 256\n",
        "batch_size = 16\n",
        "n_classes = 5"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8eqkYduIhqLM"
      },
      "source": [
        "pet_ids = df['PetID'].values\n",
        "n_batches = len(pet_ids) // batch_size + 1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "m-fPFf-shqLN"
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "# max_images = 100\n",
        "for index, row in df.iterrows():\n",
        "    # img = load_image(\"train_images/\", row['PetID'])\n",
        "    for count in range(int(row['PhotoAmt'])):\n",
        "      name = f\"{row['PetID']}-{count+1}.jpg\"\n",
        "      imgName = os.path.join(\"train_images/\", name)\n",
        "      X.append(imgName)\n",
        "      y.append(row['AdoptionSpeed'])\n",
        "    # if index > max_images:\n",
        "    #     break\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfM-NoCdnwv-",
        "outputId": "93d4718d-6104-4ed9-a44c-3df07367f0a7"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58311"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZxT0lXghqLN",
        "outputId": "6947391f-7d32-4133-f7ef-c5296536f1fc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "batch_size = 32\n",
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)\n",
        "\n",
        "my_training_batch_generator = My_Custom_Generator(x_train, y_train, batch_size)\n",
        "my_validation_batch_generator = My_Custom_Generator(x_val, y_val, batch_size)\n",
        "print(my_validation_batch_generator)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<dataset.My_Custom_Generator object at 0x7f770bcc3278>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "R_3UlOrOhqLP"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D, Dense\n",
        "import keras.backend as K\n",
        "import keras\n",
        "inp = Input((256,256,3))\n",
        "backbone = ResNet101(input_tensor = inp, include_top = False)\n",
        "# for layer in backbone.layers:\n",
        "#     layer.trainable = False\n",
        "x = backbone.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(4096)(x)\n",
        "x = Dense(4096)(x)\n",
        "out = Dense(n_classes, activation='softmax')(x)\n",
        "m = Model(inp,out)\n",
        "\n",
        "m.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.01), metrics= 'accuracy')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mYNQSJAThqLP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "787ea970-df2e-4ff2-ed7c-4efa74128b3d"
      },
      "source": [
        "m.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 16, 16, 256)  0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_relu (Activation (None, 16, 16, 256)  0           conv4_block7_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block7_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block7_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_add (Add)          (None, 16, 16, 1024) 0           conv4_block6_out[0][0]           \n",
            "                                                                 conv4_block7_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_out (Activation)   (None, 16, 16, 1024) 0           conv4_block7_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block7_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 16, 16, 256)  0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_relu (Activation (None, 16, 16, 256)  0           conv4_block8_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block8_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block8_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_add (Add)          (None, 16, 16, 1024) 0           conv4_block7_out[0][0]           \n",
            "                                                                 conv4_block8_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_out (Activation)   (None, 16, 16, 1024) 0           conv4_block8_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block8_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 16, 16, 256)  0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_relu (Activation (None, 16, 16, 256)  0           conv4_block9_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block9_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block9_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_add (Add)          (None, 16, 16, 1024) 0           conv4_block8_out[0][0]           \n",
            "                                                                 conv4_block9_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_out (Activation)   (None, 16, 16, 1024) 0           conv4_block9_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block9_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block10_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block10_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block10_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_add (Add)         (None, 16, 16, 1024) 0           conv4_block9_out[0][0]           \n",
            "                                                                 conv4_block10_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_out (Activation)  (None, 16, 16, 1024) 0           conv4_block10_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block10_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block11_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block11_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block11_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_add (Add)         (None, 16, 16, 1024) 0           conv4_block10_out[0][0]          \n",
            "                                                                 conv4_block11_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_out (Activation)  (None, 16, 16, 1024) 0           conv4_block11_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block11_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block12_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block12_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block12_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_add (Add)         (None, 16, 16, 1024) 0           conv4_block11_out[0][0]          \n",
            "                                                                 conv4_block12_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_out (Activation)  (None, 16, 16, 1024) 0           conv4_block12_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block12_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block13_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block13_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block13_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_add (Add)         (None, 16, 16, 1024) 0           conv4_block12_out[0][0]          \n",
            "                                                                 conv4_block13_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_out (Activation)  (None, 16, 16, 1024) 0           conv4_block13_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block13_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block14_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block14_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block14_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_add (Add)         (None, 16, 16, 1024) 0           conv4_block13_out[0][0]          \n",
            "                                                                 conv4_block14_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_out (Activation)  (None, 16, 16, 1024) 0           conv4_block14_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block14_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block15_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block15_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block15_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_add (Add)         (None, 16, 16, 1024) 0           conv4_block14_out[0][0]          \n",
            "                                                                 conv4_block15_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_out (Activation)  (None, 16, 16, 1024) 0           conv4_block15_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block15_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block16_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block16_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block16_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_add (Add)         (None, 16, 16, 1024) 0           conv4_block15_out[0][0]          \n",
            "                                                                 conv4_block16_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_out (Activation)  (None, 16, 16, 1024) 0           conv4_block16_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block16_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block17_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block17_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block17_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_add (Add)         (None, 16, 16, 1024) 0           conv4_block16_out[0][0]          \n",
            "                                                                 conv4_block17_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_out (Activation)  (None, 16, 16, 1024) 0           conv4_block17_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block17_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block18_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block18_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block18_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_add (Add)         (None, 16, 16, 1024) 0           conv4_block17_out[0][0]          \n",
            "                                                                 conv4_block18_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_out (Activation)  (None, 16, 16, 1024) 0           conv4_block18_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block18_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block19_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block19_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block19_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_add (Add)         (None, 16, 16, 1024) 0           conv4_block18_out[0][0]          \n",
            "                                                                 conv4_block19_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_out (Activation)  (None, 16, 16, 1024) 0           conv4_block19_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block19_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block20_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block20_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block20_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_add (Add)         (None, 16, 16, 1024) 0           conv4_block19_out[0][0]          \n",
            "                                                                 conv4_block20_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_out (Activation)  (None, 16, 16, 1024) 0           conv4_block20_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block20_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block21_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block21_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block21_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_add (Add)         (None, 16, 16, 1024) 0           conv4_block20_out[0][0]          \n",
            "                                                                 conv4_block21_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_out (Activation)  (None, 16, 16, 1024) 0           conv4_block21_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block21_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block22_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block22_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block22_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_add (Add)         (None, 16, 16, 1024) 0           conv4_block21_out[0][0]          \n",
            "                                                                 conv4_block22_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_out (Activation)  (None, 16, 16, 1024) 0           conv4_block22_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 16, 16, 256)  262400      conv4_block22_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 16, 16, 256)  0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 16, 16, 256)  590080      conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block23_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block23_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_3_bn (BatchNormal (None, 16, 16, 1024) 4096        conv4_block23_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_add (Add)         (None, 16, 16, 1024) 0           conv4_block22_out[0][0]          \n",
            "                                                                 conv4_block23_3_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_out (Activation)  (None, 16, 16, 1024) 0           conv4_block23_add[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block23_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block23_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 4096)         8392704     global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 4096)         16781312    dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 5)            20485       dense_4[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 67,852,677\n",
            "Trainable params: 67,747,333\n",
            "Non-trainable params: 105,344\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUj9eDbVhqLQ",
        "outputId": "f52700e5-ff4f-454f-87af-20acd747e4a3"
      },
      "source": [
        "m.fit_generator(generator = my_training_batch_generator,\n",
        "                steps_per_epoch = int(3800 // batch_size),\n",
        "                epochs=100, \n",
        "                validation_data = my_validation_batch_generator,\n",
        "                validation_steps = int(950 // batch_size))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "118/118 [==============================] - 162s 1s/step - loss: 228.3708 - accuracy: 0.2095 - val_loss: 4.6717 - val_accuracy: 0.3028\n",
            "Epoch 2/100\n",
            "118/118 [==============================] - 149s 1s/step - loss: 18.6842 - accuracy: 0.2586 - val_loss: 1.9579 - val_accuracy: 0.3028\n",
            "Epoch 3/100\n",
            "118/118 [==============================] - 149s 1s/step - loss: 4.8154 - accuracy: 0.2532 - val_loss: 1.4940 - val_accuracy: 0.3028\n",
            "Epoch 4/100\n",
            "118/118 [==============================] - 148s 1s/step - loss: 2.4915 - accuracy: 0.2579 - val_loss: 1.4748 - val_accuracy: 0.2694\n",
            "Epoch 5/100\n",
            "118/118 [==============================] - 151s 1s/step - loss: 1.7726 - accuracy: 0.2487 - val_loss: 1.4598 - val_accuracy: 0.2694\n",
            "Epoch 6/100\n",
            "118/118 [==============================] - 150s 1s/step - loss: 1.5810 - accuracy: 0.2726 - val_loss: 1.4580 - val_accuracy: 0.2220\n",
            "Epoch 7/100\n",
            "118/118 [==============================] - 149s 1s/step - loss: 1.5065 - accuracy: 0.2785 - val_loss: 1.4564 - val_accuracy: 0.2694\n",
            "Epoch 8/100\n",
            "118/118 [==============================] - 148s 1s/step - loss: 1.5106 - accuracy: 0.2625 - val_loss: 1.4675 - val_accuracy: 0.3028\n",
            "Epoch 9/100\n",
            "118/118 [==============================] - 148s 1s/step - loss: 1.5215 - accuracy: 0.2542 - val_loss: 1.4623 - val_accuracy: 0.3028\n",
            "Epoch 10/100\n",
            "118/118 [==============================] - 148s 1s/step - loss: 1.5176 - accuracy: 0.2784 - val_loss: 1.4890 - val_accuracy: 0.2694\n",
            "Epoch 11/100\n",
            "118/118 [==============================] - 148s 1s/step - loss: 1.5673 - accuracy: 0.2809 - val_loss: 1.4769 - val_accuracy: 0.2220\n",
            "Epoch 12/100\n",
            "118/118 [==============================] - 147s 1s/step - loss: 1.7276 - accuracy: 0.2572 - val_loss: 1.5346 - val_accuracy: 0.2694\n",
            "Epoch 13/100\n",
            "118/118 [==============================] - 148s 1s/step - loss: 1.9005 - accuracy: 0.2555 - val_loss: 1.7477 - val_accuracy: 0.2220\n",
            "Epoch 14/100\n",
            "118/118 [==============================] - 148s 1s/step - loss: 3.5696 - accuracy: 0.2727 - val_loss: 1.5569 - val_accuracy: 0.1832\n",
            "Epoch 15/100\n",
            "118/118 [==============================] - 147s 1s/step - loss: 8.5494 - accuracy: 0.2498 - val_loss: 1.5034 - val_accuracy: 0.3028\n",
            "Epoch 16/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 3.3913 - accuracy: 0.2524 - val_loss: 2.0763 - val_accuracy: 0.2888\n",
            "Epoch 17/100\n",
            "118/118 [==============================] - 147s 1s/step - loss: 2.4990 - accuracy: 0.2699 - val_loss: 1.5774 - val_accuracy: 0.2996\n",
            "Epoch 18/100\n",
            "118/118 [==============================] - 147s 1s/step - loss: 1.6305 - accuracy: 0.2847 - val_loss: 1.4792 - val_accuracy: 0.2974\n",
            "Epoch 19/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 1.4910 - accuracy: 0.2934 - val_loss: 1.4751 - val_accuracy: 0.2953\n",
            "Epoch 20/100\n",
            "118/118 [==============================] - 147s 1s/step - loss: 1.4821 - accuracy: 0.2787 - val_loss: 1.4586 - val_accuracy: 0.2985\n",
            "Epoch 21/100\n",
            "118/118 [==============================] - 148s 1s/step - loss: 1.4732 - accuracy: 0.2896 - val_loss: 1.4569 - val_accuracy: 0.3006\n",
            "Epoch 22/100\n",
            "118/118 [==============================] - 147s 1s/step - loss: 1.4704 - accuracy: 0.2831 - val_loss: 1.4654 - val_accuracy: 0.2996\n",
            "Epoch 23/100\n",
            "118/118 [==============================] - 149s 1s/step - loss: 1.4706 - accuracy: 0.2847 - val_loss: 1.4880 - val_accuracy: 0.3028\n",
            "Epoch 24/100\n",
            "118/118 [==============================] - 149s 1s/step - loss: 1.4693 - accuracy: 0.2481 - val_loss: 1.4530 - val_accuracy: 0.3006\n",
            "Epoch 25/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 1.4839 - accuracy: 0.2783 - val_loss: 1.5112 - val_accuracy: 0.3006\n",
            "Epoch 26/100\n",
            "118/118 [==============================] - 148s 1s/step - loss: 1.5038 - accuracy: 0.2703 - val_loss: 1.4574 - val_accuracy: 0.3006\n",
            "Epoch 27/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 1.4431 - accuracy: 0.2837 - val_loss: 1.5609 - val_accuracy: 0.2705\n",
            "Epoch 28/100\n",
            "118/118 [==============================] - 147s 1s/step - loss: 1.4851 - accuracy: 0.2768 - val_loss: 1.5572 - val_accuracy: 0.2996\n",
            "Epoch 29/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 1.4726 - accuracy: 0.2960 - val_loss: 1.4970 - val_accuracy: 0.3006\n",
            "Epoch 30/100\n",
            "118/118 [==============================] - 148s 1s/step - loss: 1.4599 - accuracy: 0.2853 - val_loss: 1.5812 - val_accuracy: 0.2716\n",
            "Epoch 31/100\n",
            "118/118 [==============================] - 145s 1s/step - loss: 1.5323 - accuracy: 0.2608 - val_loss: 1.5819 - val_accuracy: 0.3006\n",
            "Epoch 32/100\n",
            "118/118 [==============================] - 145s 1s/step - loss: 1.4921 - accuracy: 0.2510 - val_loss: 2.8836 - val_accuracy: 0.2996\n",
            "Epoch 33/100\n",
            "118/118 [==============================] - 145s 1s/step - loss: 1.4911 - accuracy: 0.2814 - val_loss: 1.4803 - val_accuracy: 0.3028\n",
            "Epoch 34/100\n",
            "118/118 [==============================] - 145s 1s/step - loss: 1.4833 - accuracy: 0.2719 - val_loss: 1.6123 - val_accuracy: 0.1843\n",
            "Epoch 35/100\n",
            "118/118 [==============================] - 144s 1s/step - loss: 1.6747 - accuracy: 0.2473 - val_loss: 2.9060 - val_accuracy: 0.2759\n",
            "Epoch 36/100\n",
            "118/118 [==============================] - 145s 1s/step - loss: 1.5368 - accuracy: 0.2531 - val_loss: 29.4334 - val_accuracy: 0.1983\n",
            "Epoch 37/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 1.5165 - accuracy: 0.2454 - val_loss: 10.7669 - val_accuracy: 0.2554\n",
            "Epoch 38/100\n",
            "118/118 [==============================] - 144s 1s/step - loss: 1.4878 - accuracy: 0.2613 - val_loss: 1.4566 - val_accuracy: 0.3028\n",
            "Epoch 39/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 1.4823 - accuracy: 0.2809 - val_loss: 1.4906 - val_accuracy: 0.2220\n",
            "Epoch 40/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 1.4950 - accuracy: 0.2684 - val_loss: 1.6119 - val_accuracy: 0.2996\n",
            "Epoch 41/100\n",
            "118/118 [==============================] - 148s 1s/step - loss: 2.1463 - accuracy: 0.2667 - val_loss: 17079388.0000 - val_accuracy: 0.0226\n",
            "Epoch 42/100\n",
            "118/118 [==============================] - 147s 1s/step - loss: 6766.7250 - accuracy: 0.2250 - val_loss: 5603705856.0000 - val_accuracy: 0.2694\n",
            "Epoch 43/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 99.7055 - accuracy: 0.2303 - val_loss: 102293.0938 - val_accuracy: 0.2532\n",
            "Epoch 44/100\n",
            "118/118 [==============================] - 145s 1s/step - loss: 9.4587 - accuracy: 0.2323 - val_loss: 688.1367 - val_accuracy: 0.2920\n",
            "Epoch 45/100\n",
            "118/118 [==============================] - 147s 1s/step - loss: 6.4294 - accuracy: 0.2481 - val_loss: 129.2074 - val_accuracy: 0.2241\n",
            "Epoch 46/100\n",
            "118/118 [==============================] - 144s 1s/step - loss: 3.4994 - accuracy: 0.2459 - val_loss: 265.0275 - val_accuracy: 0.3006\n",
            "Epoch 47/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 4.1977 - accuracy: 0.2327 - val_loss: 444.5782 - val_accuracy: 0.2672\n",
            "Epoch 48/100\n",
            "118/118 [==============================] - 147s 1s/step - loss: 3.7939 - accuracy: 0.2448 - val_loss: 60.4050 - val_accuracy: 0.2629\n",
            "Epoch 49/100\n",
            "118/118 [==============================] - 147s 1s/step - loss: 2.8336 - accuracy: 0.2472 - val_loss: 90.6334 - val_accuracy: 0.2241\n",
            "Epoch 50/100\n",
            "118/118 [==============================] - 145s 1s/step - loss: 3.8966 - accuracy: 0.2479 - val_loss: 238.0245 - val_accuracy: 0.2274\n",
            "Epoch 51/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 3.2260 - accuracy: 0.2642 - val_loss: 235.4084 - val_accuracy: 0.2640\n",
            "Epoch 52/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 3.1864 - accuracy: 0.2684 - val_loss: 145.8055 - val_accuracy: 0.2198\n",
            "Epoch 53/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 2.7257 - accuracy: 0.2609 - val_loss: 68.0853 - val_accuracy: 0.2629\n",
            "Epoch 54/100\n",
            "118/118 [==============================] - 145s 1s/step - loss: 2.6795 - accuracy: 0.2189 - val_loss: 97.7687 - val_accuracy: 0.2651\n",
            "Epoch 55/100\n",
            "118/118 [==============================] - 147s 1s/step - loss: 3.8668 - accuracy: 0.2526 - val_loss: 20.2936 - val_accuracy: 0.3017\n",
            "Epoch 56/100\n",
            "118/118 [==============================] - 145s 1s/step - loss: 3.4330 - accuracy: 0.2505 - val_loss: 99.1875 - val_accuracy: 0.1864\n",
            "Epoch 57/100\n",
            "118/118 [==============================] - 147s 1s/step - loss: 3.0925 - accuracy: 0.2557 - val_loss: 73.7220 - val_accuracy: 0.2985\n",
            "Epoch 58/100\n",
            "118/118 [==============================] - 147s 1s/step - loss: 3.4969 - accuracy: 0.2865 - val_loss: 179.6617 - val_accuracy: 0.3028\n",
            "Epoch 59/100\n",
            "118/118 [==============================] - 147s 1s/step - loss: 2.8621 - accuracy: 0.2639 - val_loss: 284.0105 - val_accuracy: 0.2963\n",
            "Epoch 60/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 3.2205 - accuracy: 0.2703 - val_loss: 231.3669 - val_accuracy: 0.2996\n",
            "Epoch 61/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 2.7510 - accuracy: 0.2534 - val_loss: 50.1920 - val_accuracy: 0.2683\n",
            "Epoch 62/100\n",
            "118/118 [==============================] - 144s 1s/step - loss: 3.6679 - accuracy: 0.2794 - val_loss: 403.7757 - val_accuracy: 0.2662\n",
            "Epoch 63/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 5.7351 - accuracy: 0.2515 - val_loss: 227.1151 - val_accuracy: 0.2220\n",
            "Epoch 64/100\n",
            "118/118 [==============================] - 145s 1s/step - loss: 4.6285 - accuracy: 0.2348 - val_loss: 332.1643 - val_accuracy: 0.2672\n",
            "Epoch 65/100\n",
            "118/118 [==============================] - 144s 1s/step - loss: 5.9934 - accuracy: 0.2603 - val_loss: 70.6885 - val_accuracy: 0.2662\n",
            "Epoch 66/100\n",
            "118/118 [==============================] - 145s 1s/step - loss: 4.9926 - accuracy: 0.2665 - val_loss: 167.2154 - val_accuracy: 0.2662\n",
            "Epoch 67/100\n",
            "118/118 [==============================] - 147s 1s/step - loss: 2.6945 - accuracy: 0.2481 - val_loss: 77.1694 - val_accuracy: 0.2996\n",
            "Epoch 68/100\n",
            "118/118 [==============================] - 148s 1s/step - loss: 3.1587 - accuracy: 0.2732 - val_loss: 36.0771 - val_accuracy: 0.2953\n",
            "Epoch 69/100\n",
            "118/118 [==============================] - 145s 1s/step - loss: 3.3279 - accuracy: 0.2518 - val_loss: 51.0681 - val_accuracy: 0.3050\n",
            "Epoch 70/100\n",
            "118/118 [==============================] - 144s 1s/step - loss: 2.6952 - accuracy: 0.2619 - val_loss: 6.0903 - val_accuracy: 0.1853\n",
            "Epoch 71/100\n",
            "118/118 [==============================] - 149s 1s/step - loss: 2.3272 - accuracy: 0.2528 - val_loss: 147.9977 - val_accuracy: 0.2953\n",
            "Epoch 72/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 2.0530 - accuracy: 0.2352 - val_loss: 52.5868 - val_accuracy: 0.2683\n",
            "Epoch 73/100\n",
            "118/118 [==============================] - 144s 1s/step - loss: 2.8217 - accuracy: 0.2517 - val_loss: 84.6570 - val_accuracy: 0.2640\n",
            "Epoch 74/100\n",
            "118/118 [==============================] - 144s 1s/step - loss: 2.3885 - accuracy: 0.2624 - val_loss: 2025.6886 - val_accuracy: 0.1907\n",
            "Epoch 75/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 2.2027 - accuracy: 0.2482 - val_loss: 206.6655 - val_accuracy: 0.2198\n",
            "Epoch 76/100\n",
            "118/118 [==============================] - 145s 1s/step - loss: 2.4269 - accuracy: 0.2538 - val_loss: 281.2365 - val_accuracy: 0.2974\n",
            "Epoch 77/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 2.4946 - accuracy: 0.2502 - val_loss: 617.2899 - val_accuracy: 0.2662\n",
            "Epoch 78/100\n",
            "118/118 [==============================] - 145s 1s/step - loss: 2.1449 - accuracy: 0.2468 - val_loss: 272.6572 - val_accuracy: 0.2963\n",
            "Epoch 79/100\n",
            "118/118 [==============================] - 145s 1s/step - loss: 2.1273 - accuracy: 0.2725 - val_loss: 31.7976 - val_accuracy: 0.3028\n",
            "Epoch 80/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 1.9424 - accuracy: 0.2680 - val_loss: 28.1683 - val_accuracy: 0.2996\n",
            "Epoch 81/100\n",
            "118/118 [==============================] - 144s 1s/step - loss: 2.3857 - accuracy: 0.2445 - val_loss: 8.1532 - val_accuracy: 0.2748\n",
            "Epoch 82/100\n",
            "118/118 [==============================] - 143s 1s/step - loss: 2.0661 - accuracy: 0.2377 - val_loss: 7.0776 - val_accuracy: 0.3039\n",
            "Epoch 83/100\n",
            "118/118 [==============================] - 144s 1s/step - loss: 1.9132 - accuracy: 0.2523 - val_loss: 619.5110 - val_accuracy: 0.3103\n",
            "Epoch 84/100\n",
            "118/118 [==============================] - 144s 1s/step - loss: 1.9655 - accuracy: 0.2641 - val_loss: 250.7402 - val_accuracy: 0.2662\n",
            "Epoch 85/100\n",
            "118/118 [==============================] - 143s 1s/step - loss: 2.3047 - accuracy: 0.2462 - val_loss: 182.3307 - val_accuracy: 0.2672\n",
            "Epoch 86/100\n",
            "118/118 [==============================] - 144s 1s/step - loss: 1.7922 - accuracy: 0.2665 - val_loss: 19.8832 - val_accuracy: 0.3060\n",
            "Epoch 87/100\n",
            "118/118 [==============================] - 145s 1s/step - loss: 1.6437 - accuracy: 0.2708 - val_loss: 73.6978 - val_accuracy: 0.3028\n",
            "Epoch 88/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 1.6915 - accuracy: 0.2733 - val_loss: 73.9376 - val_accuracy: 0.2640\n",
            "Epoch 89/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 1.5770 - accuracy: 0.2748 - val_loss: 19.8198 - val_accuracy: 0.3028\n",
            "Epoch 90/100\n",
            "118/118 [==============================] - 145s 1s/step - loss: 1.6036 - accuracy: 0.2462 - val_loss: 16.8771 - val_accuracy: 0.3006\n",
            "Epoch 91/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 1.5845 - accuracy: 0.2689 - val_loss: 29.4486 - val_accuracy: 0.2716\n",
            "Epoch 92/100\n",
            "118/118 [==============================] - 146s 1s/step - loss: 1.6258 - accuracy: 0.2779 - val_loss: 34.7574 - val_accuracy: 0.2231\n",
            "Epoch 93/100\n",
            "118/118 [==============================] - 144s 1s/step - loss: 1.5535 - accuracy: 0.2654 - val_loss: 23.2381 - val_accuracy: 0.3060\n",
            "Epoch 94/100\n",
            "118/118 [==============================] - 144s 1s/step - loss: 1.5237 - accuracy: 0.2771 - val_loss: 25.0036 - val_accuracy: 0.3028\n",
            "Epoch 95/100\n",
            "118/118 [==============================] - 143s 1s/step - loss: 1.5032 - accuracy: 0.2739 - val_loss: 35.6639 - val_accuracy: 0.3017\n",
            "Epoch 96/100\n",
            "118/118 [==============================] - 144s 1s/step - loss: 1.6149 - accuracy: 0.2615 - val_loss: 27.8956 - val_accuracy: 0.2672\n",
            "Epoch 97/100\n",
            "118/118 [==============================] - 143s 1s/step - loss: 1.7652 - accuracy: 0.2695 - val_loss: 36.1758 - val_accuracy: 0.3060\n",
            "Epoch 98/100\n",
            "118/118 [==============================] - 143s 1s/step - loss: 1.5743 - accuracy: 0.2751 - val_loss: 56.7563 - val_accuracy: 0.2220\n",
            "Epoch 99/100\n",
            "118/118 [==============================] - 143s 1s/step - loss: 1.5624 - accuracy: 0.2518 - val_loss: 23.2878 - val_accuracy: 0.2241\n",
            "Epoch 100/100\n",
            "118/118 [==============================] - 142s 1s/step - loss: 1.4703 - accuracy: 0.2659 - val_loss: 6.2245 - val_accuracy: 0.3050\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f76a39e2e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}