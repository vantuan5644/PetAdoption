{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "petfinder.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "sZ41r-AAnBco"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBDLO2K_lPgq",
        "outputId": "8c86ffb0-e7c7-4b9a-f90d-080cd978913e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D6Z64TCnPgF",
        "outputId": "140029ee-d0e5-473b-afa4-9a5fc27be970"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6ON0ynZlcHX"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/petfinder ./"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6WFtmnonZTP",
        "outputId": "67d96346-6cc0-4978-a71d-ccc789f3d017"
      },
      "source": [
        "%cd petfinder"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/petfinder\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TLFzWGzloB1"
      },
      "source": [
        "!unzip -qq petfinder-adoption-prediction.zip"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCHkL5XtKHOc",
        "outputId": "2326dbd7-eacb-4bbd-dd2d-69a38b3e5ba0"
      },
      "source": [
        "!unzip -qq /content/petfinder/glove.840B.300d.txt.zip"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace glove.840B.300d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGdqmZ3YnTMB"
      },
      "source": [
        "!unzip -qq /content/petfinder/archive.zip"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "2l4_okFGhqK_"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.applications.resnet import preprocess_input, ResNet101\n",
        "from keras.utils import to_categorical\n",
        "from dataset import My_Custom_Generator"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "IvB-MPxehqLE",
        "outputId": "fab74d53-ea4c-4b47-8028-a0b08a9642c1"
      },
      "source": [
        "path = 'train/train.csv'\n",
        "df_pet = pd.read_csv(path)\n",
        "df = df_pet[['PetID','PhotoAmt','AdoptionSpeed','Description']]\n",
        "df = df[df['PhotoAmt']>0]\n",
        "df.head()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PetID</th>\n",
              "      <th>PhotoAmt</th>\n",
              "      <th>AdoptionSpeed</th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86e1089a3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6296e909a</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>I just found it alone yesterday near my apartm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3422e4906</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3</td>\n",
              "      <td>Their pregnant mother was dumped by her irresp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5842f1ff5</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2</td>\n",
              "      <td>Good guard dog, very alert, active, obedience ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850a43f90</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>This handsome yet cute boy is up for adoption....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       PetID  ...                                        Description\n",
              "0  86e1089a3  ...  Nibble is a 3+ month old ball of cuteness. He ...\n",
              "1  6296e909a  ...  I just found it alone yesterday near my apartm...\n",
              "2  3422e4906  ...  Their pregnant mother was dumped by her irresp...\n",
              "3  5842f1ff5  ...  Good guard dog, very alert, active, obedience ...\n",
              "4  850a43f90  ...  This handsome yet cute boy is up for adoption....\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "vGCVdRsshqLI",
        "outputId": "b6887875-d15a-4e0a-8ba3-7763dd4c3ee6"
      },
      "source": [
        "df['AdoptionSpeed'].value_counts().plot(kind='bar')\n",
        "plt.title(\"Distrubition of label\")\n",
        "plt.show()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ41r-AAnBco"
      },
      "source": [
        "# CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5NwIBBi4hqLJ"
      },
      "source": [
        "def resize_to_square(im):\n",
        "    old_size = im.shape[:2] # old_size is in (height, width) format\n",
        "    ratio = float(img_size)/max(old_size)\n",
        "    new_size = tuple([int(x*ratio) for x in old_size])\n",
        "    # new_size should be in (width, height) format\n",
        "    im = cv2.resize(im, (new_size[1], new_size[0]))\n",
        "    delta_w = img_size - new_size[1]\n",
        "    delta_h = img_size - new_size[0]\n",
        "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
        "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
        "    color = [0, 0, 0]\n",
        "    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
        "    return new_im\n",
        "\n",
        "def load_image(path, pet_id):\n",
        "    image = cv2.imread(f'{path}{pet_id}-1.jpg')\n",
        "    new_image = resize_to_square(image)\n",
        "    new_image = preprocess_input(new_image)\n",
        "    return new_image\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Lgpi-vZghqLL"
      },
      "source": [
        "# img_size = 256\n",
        "# batch_size = 16\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8eqkYduIhqLM"
      },
      "source": [
        "# pet_ids = df['PetID'].values\n",
        "# n_batches = len(pet_ids) // batch_size + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "m-fPFf-shqLN"
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "# max_images = 100\n",
        "for index, row in df.iterrows():\n",
        "    # img = load_image(\"train_images/\", row['PetID'])\n",
        "    for count in range(int(row['PhotoAmt'])):\n",
        "      name = f\"{row['PetID']}-{count+1}.jpg\"\n",
        "      imgName = os.path.join(\"train_images/\", name)\n",
        "      X.append(imgName)\n",
        "      y.append(row['AdoptionSpeed'])\n",
        "    # if index > max_images:\n",
        "    #     break\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfM-NoCdnwv-",
        "outputId": "5b219e43-e112-404a-f7ad-35fd793d65c9"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58311"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZxT0lXghqLN",
        "outputId": "a6b1ae11-700e-4160-c102-cef492f1822d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "batch_size = 32\n",
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)\n",
        "\n",
        "my_training_batch_generator = My_Custom_Generator(x_train, y_train, batch_size)\n",
        "my_validation_batch_generator = My_Custom_Generator(x_val, y_val, batch_size)\n",
        "print(my_validation_batch_generator)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<dataset.My_Custom_Generator object at 0x7f021b601240>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "R_3UlOrOhqLP"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D, Dense, Conv2D, MaxPooling2D\n",
        "import keras.backend as K\n",
        "import keras\n",
        "epochs = 100\n",
        "lr = 0.0001\n",
        "decay_rate = lr / epochs\n",
        "n_classes = 5\n",
        "inp = Input((256,256,3))\n",
        "\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(inp)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(3, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "backbone = ResNet101(include_top = False, weights=\"imagenet\")(encoded)\n",
        "# for layer in backbone.layers:\n",
        "#     layer.trainable = False\n",
        "x = GlobalAveragePooling2D()(backbone)\n",
        "x = Dense(4096)(x)\n",
        "x = Dense(4096)(x)\n",
        "out = Dense(n_classes, activation='softmax')(x)\n",
        "m = Model(inp,out)\n",
        "\n",
        "m.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=lr, decay=decay_rate), metrics= 'accuracy')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mYNQSJAThqLP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb720e6-bcb1-4bf2-e5a9-59293adae774"
      },
      "source": [
        "m.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_28 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_57 (Conv2D)           (None, 256, 256, 128)     3584      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_57 (MaxPooling (None, 128, 128, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 128, 128, 64)      73792     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_58 (MaxPooling (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_59 (Conv2D)           (None, 64, 64, 3)         1731      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_59 (MaxPooling (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "resnet101 (Functional)       (None, None, None, 2048)  42658176  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 4096)              8392704   \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 5)                 20485     \n",
            "=================================================================\n",
            "Total params: 67,931,784\n",
            "Trainable params: 67,826,440\n",
            "Non-trainable params: 105,344\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "oUj9eDbVhqLQ",
        "outputId": "bee90e35-2036-4dc4-ac5b-953f220fc448"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "filepath=\"/content/drive/MyDrive/petfinder/weights\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "m.fit_generator(generator = my_training_batch_generator,\n",
        "                steps_per_epoch = int(3800 // batch_size),\n",
        "                epochs=epochs, \n",
        "                validation_data = my_validation_batch_generator,\n",
        "                validation_steps = int(950 // batch_size),\n",
        "                callbacks=callbacks_list)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "118/118 [==============================] - 143s 1s/step - loss: 2.9604 - accuracy: 0.2213 - val_loss: 150.0901 - val_accuracy: 0.1832\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.18319, saving model to /content/drive/MyDrive/petfinder/weights\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/petfinder/weights/assets\n",
            "Epoch 2/100\n",
            "118/118 [==============================] - 133s 1s/step - loss: 2.0895 - accuracy: 0.2590 - val_loss: 7488.6030 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.18319 to 0.30280, saving model to /content/drive/MyDrive/petfinder/weights\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/petfinder/weights/assets\n",
            "Epoch 3/100\n",
            "118/118 [==============================] - 132s 1s/step - loss: 1.9428 - accuracy: 0.2408 - val_loss: 19875.1602 - val_accuracy: 0.2694\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.30280\n",
            "Epoch 4/100\n",
            "118/118 [==============================] - 129s 1s/step - loss: 1.5473 - accuracy: 0.2658 - val_loss: 41255.1289 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.30280\n",
            "Epoch 5/100\n",
            "118/118 [==============================] - 130s 1s/step - loss: 1.5392 - accuracy: 0.2763 - val_loss: 31185.1289 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.30280\n",
            "Epoch 6/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.5522 - accuracy: 0.2785 - val_loss: 16374.0137 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.30280\n",
            "Epoch 7/100\n",
            "118/118 [==============================] - 129s 1s/step - loss: 1.5341 - accuracy: 0.2699 - val_loss: 40628.9609 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.30280\n",
            "Epoch 8/100\n",
            "118/118 [==============================] - 129s 1s/step - loss: 1.5139 - accuracy: 0.2821 - val_loss: 30181.7500 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.30280\n",
            "Epoch 9/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4945 - accuracy: 0.2792 - val_loss: 25675.5684 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.30280\n",
            "Epoch 10/100\n",
            "118/118 [==============================] - 127s 1s/step - loss: 1.4854 - accuracy: 0.2747 - val_loss: 39202.7617 - val_accuracy: 0.2694\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.30280\n",
            "Epoch 11/100\n",
            "118/118 [==============================] - 127s 1s/step - loss: 1.4843 - accuracy: 0.2598 - val_loss: 13104.0801 - val_accuracy: 0.1832\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.30280\n",
            "Epoch 12/100\n",
            "118/118 [==============================] - 126s 1s/step - loss: 1.4674 - accuracy: 0.2796 - val_loss: 7158.9434 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.30280\n",
            "Epoch 13/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4779 - accuracy: 0.2945 - val_loss: 345.7473 - val_accuracy: 0.2220\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.30280\n",
            "Epoch 14/100\n",
            "118/118 [==============================] - 127s 1s/step - loss: 1.4849 - accuracy: 0.2598 - val_loss: 2485.1995 - val_accuracy: 0.0226\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.30280\n",
            "Epoch 15/100\n",
            "118/118 [==============================] - 127s 1s/step - loss: 1.6137 - accuracy: 0.2805 - val_loss: 190.7502 - val_accuracy: 0.1832\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.30280\n",
            "Epoch 16/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.5364 - accuracy: 0.2761 - val_loss: 1.4491 - val_accuracy: 0.2716\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.30280\n",
            "Epoch 17/100\n",
            "118/118 [==============================] - 127s 1s/step - loss: 1.4876 - accuracy: 0.2613 - val_loss: 29.4524 - val_accuracy: 0.2694\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.30280\n",
            "Epoch 18/100\n",
            "118/118 [==============================] - 127s 1s/step - loss: 1.4609 - accuracy: 0.2789 - val_loss: 732.3793 - val_accuracy: 0.2694\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.30280\n",
            "Epoch 19/100\n",
            "118/118 [==============================] - 127s 1s/step - loss: 1.4722 - accuracy: 0.2775 - val_loss: 1.4532 - val_accuracy: 0.3006\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.30280\n",
            "Epoch 20/100\n",
            "118/118 [==============================] - 127s 1s/step - loss: 1.4767 - accuracy: 0.2620 - val_loss: 1.4470 - val_accuracy: 0.2683\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.30280\n",
            "Epoch 21/100\n",
            "118/118 [==============================] - 127s 1s/step - loss: 1.4620 - accuracy: 0.2793 - val_loss: 1.5582 - val_accuracy: 0.2974\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.30280\n",
            "Epoch 22/100\n",
            "118/118 [==============================] - 126s 1s/step - loss: 1.4676 - accuracy: 0.2772 - val_loss: 1.4499 - val_accuracy: 0.3039\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.30280 to 0.30388, saving model to /content/drive/MyDrive/petfinder/weights\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/petfinder/weights/assets\n",
            "Epoch 23/100\n",
            "118/118 [==============================] - 127s 1s/step - loss: 1.4617 - accuracy: 0.2861 - val_loss: 5.0521 - val_accuracy: 0.2985\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.30388\n",
            "Epoch 24/100\n",
            "118/118 [==============================] - 127s 1s/step - loss: 1.4631 - accuracy: 0.2612 - val_loss: 1.4820 - val_accuracy: 0.3050\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.30388 to 0.30496, saving model to /content/drive/MyDrive/petfinder/weights\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/petfinder/weights/assets\n",
            "Epoch 25/100\n",
            "118/118 [==============================] - 129s 1s/step - loss: 1.4617 - accuracy: 0.2677 - val_loss: 1.4497 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.30496\n",
            "Epoch 26/100\n",
            "118/118 [==============================] - 129s 1s/step - loss: 1.4647 - accuracy: 0.2542 - val_loss: 1.4525 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.30496\n",
            "Epoch 27/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4697 - accuracy: 0.2800 - val_loss: 37868.3203 - val_accuracy: 0.1832\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.30496\n",
            "Epoch 28/100\n",
            "118/118 [==============================] - 130s 1s/step - loss: 1.4607 - accuracy: 0.2718 - val_loss: 2.3217 - val_accuracy: 0.2231\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.30496\n",
            "Epoch 29/100\n",
            "118/118 [==============================] - 129s 1s/step - loss: 1.4658 - accuracy: 0.2501 - val_loss: 1.4940 - val_accuracy: 0.2694\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.30496\n",
            "Epoch 30/100\n",
            "118/118 [==============================] - 129s 1s/step - loss: 1.4526 - accuracy: 0.2712 - val_loss: 1.4597 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.30496\n",
            "Epoch 31/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.8065 - accuracy: 0.2678 - val_loss: 14.9142 - val_accuracy: 0.1832\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.30496\n",
            "Epoch 32/100\n",
            "118/118 [==============================] - 129s 1s/step - loss: 1.5118 - accuracy: 0.2656 - val_loss: 3.8452 - val_accuracy: 0.2802\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.30496\n",
            "Epoch 33/100\n",
            "118/118 [==============================] - 129s 1s/step - loss: 1.4977 - accuracy: 0.2764 - val_loss: 2.5197 - val_accuracy: 0.2769\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.30496\n",
            "Epoch 34/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4612 - accuracy: 0.2860 - val_loss: 4.7142 - val_accuracy: 0.2791\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.30496\n",
            "Epoch 35/100\n",
            "118/118 [==============================] - 127s 1s/step - loss: 1.4635 - accuracy: 0.2892 - val_loss: 1.4673 - val_accuracy: 0.2694\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.30496\n",
            "Epoch 36/100\n",
            "118/118 [==============================] - 126s 1s/step - loss: 1.4519 - accuracy: 0.2738 - val_loss: 1.5006 - val_accuracy: 0.2899\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.30496\n",
            "Epoch 37/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4591 - accuracy: 0.2648 - val_loss: 1.4831 - val_accuracy: 0.2241\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.30496\n",
            "Epoch 38/100\n",
            "118/118 [==============================] - 127s 1s/step - loss: 1.4629 - accuracy: 0.2634 - val_loss: 1.6112 - val_accuracy: 0.2963\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.30496\n",
            "Epoch 39/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4585 - accuracy: 0.2889 - val_loss: 1.4478 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.30496\n",
            "Epoch 40/100\n",
            "118/118 [==============================] - 127s 1s/step - loss: 1.4666 - accuracy: 0.2738 - val_loss: 1.4494 - val_accuracy: 0.2942\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.30496\n",
            "Epoch 41/100\n",
            "118/118 [==============================] - 127s 1s/step - loss: 1.4558 - accuracy: 0.2726 - val_loss: 1.4484 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.30496\n",
            "Epoch 42/100\n",
            "118/118 [==============================] - 127s 1s/step - loss: 1.4634 - accuracy: 0.2822 - val_loss: 1.4545 - val_accuracy: 0.3039\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.30496\n",
            "Epoch 43/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4598 - accuracy: 0.2871 - val_loss: 1.4480 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.30496\n",
            "Epoch 44/100\n",
            "118/118 [==============================] - 127s 1s/step - loss: 1.4626 - accuracy: 0.2793 - val_loss: 1.4488 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.30496\n",
            "Epoch 45/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4615 - accuracy: 0.2805 - val_loss: 1.4552 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.30496\n",
            "Epoch 46/100\n",
            "118/118 [==============================] - 127s 1s/step - loss: 1.4733 - accuracy: 0.2757 - val_loss: 1.4952 - val_accuracy: 0.2726\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.30496\n",
            "Epoch 47/100\n",
            "118/118 [==============================] - 127s 1s/step - loss: 1.4727 - accuracy: 0.2763 - val_loss: 12.9288 - val_accuracy: 0.2694\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.30496\n",
            "Epoch 48/100\n",
            "118/118 [==============================] - 127s 1s/step - loss: 1.4671 - accuracy: 0.2951 - val_loss: 1.4515 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.30496\n",
            "Epoch 49/100\n",
            "118/118 [==============================] - 126s 1s/step - loss: 1.4739 - accuracy: 0.2690 - val_loss: 1.4505 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.30496\n",
            "Epoch 50/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4857 - accuracy: 0.2874 - val_loss: 1.4482 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.30496\n",
            "Epoch 51/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4889 - accuracy: 0.2593 - val_loss: 1.4492 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.30496\n",
            "Epoch 52/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4705 - accuracy: 0.2894 - val_loss: 1.4511 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.30496\n",
            "Epoch 53/100\n",
            "118/118 [==============================] - 129s 1s/step - loss: 1.4737 - accuracy: 0.2637 - val_loss: 51.6876 - val_accuracy: 0.0647\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.30496\n",
            "Epoch 54/100\n",
            "118/118 [==============================] - 127s 1s/step - loss: 1.4579 - accuracy: 0.2743 - val_loss: 36.1581 - val_accuracy: 0.1832\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.30496\n",
            "Epoch 55/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4668 - accuracy: 0.2740 - val_loss: 1.4484 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.30496\n",
            "Epoch 56/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4536 - accuracy: 0.2974 - val_loss: 1.4496 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.30496\n",
            "Epoch 57/100\n",
            "118/118 [==============================] - 129s 1s/step - loss: 1.4603 - accuracy: 0.2888 - val_loss: 1.4481 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.30496\n",
            "Epoch 58/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4685 - accuracy: 0.2739 - val_loss: 1.5090 - val_accuracy: 0.2694\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.30496\n",
            "Epoch 59/100\n",
            "118/118 [==============================] - 129s 1s/step - loss: 1.4656 - accuracy: 0.2758 - val_loss: 1.6093 - val_accuracy: 0.1832\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.30496\n",
            "Epoch 60/100\n",
            "118/118 [==============================] - 129s 1s/step - loss: 1.4594 - accuracy: 0.2877 - val_loss: 1.4541 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.30496\n",
            "Epoch 61/100\n",
            "118/118 [==============================] - 129s 1s/step - loss: 1.4694 - accuracy: 0.2693 - val_loss: 1.4479 - val_accuracy: 0.3039\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.30496\n",
            "Epoch 62/100\n",
            "118/118 [==============================] - 129s 1s/step - loss: 1.4682 - accuracy: 0.2675 - val_loss: 38.4775 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.30496\n",
            "Epoch 63/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4658 - accuracy: 0.2555 - val_loss: 71.7336 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.30496\n",
            "Epoch 64/100\n",
            "118/118 [==============================] - 129s 1s/step - loss: 1.4856 - accuracy: 0.2625 - val_loss: 29.7428 - val_accuracy: 0.2220\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.30496\n",
            "Epoch 65/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4523 - accuracy: 0.2827 - val_loss: 1.6134 - val_accuracy: 0.2963\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.30496\n",
            "Epoch 66/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4666 - accuracy: 0.2844 - val_loss: 1.4523 - val_accuracy: 0.3017\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.30496\n",
            "Epoch 67/100\n",
            "118/118 [==============================] - 127s 1s/step - loss: 1.4644 - accuracy: 0.2919 - val_loss: 1.4491 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.30496\n",
            "Epoch 68/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4406 - accuracy: 0.2779 - val_loss: 1.4478 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.30496\n",
            "Epoch 69/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4589 - accuracy: 0.2669 - val_loss: 1.4476 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.30496\n",
            "Epoch 70/100\n",
            "118/118 [==============================] - 129s 1s/step - loss: 1.4665 - accuracy: 0.2542 - val_loss: 2.0077 - val_accuracy: 0.2856\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.30496\n",
            "Epoch 71/100\n",
            "118/118 [==============================] - 129s 1s/step - loss: 1.4652 - accuracy: 0.2794 - val_loss: 1.4501 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.30496\n",
            "Epoch 72/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4672 - accuracy: 0.2855 - val_loss: 1.4541 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.30496\n",
            "Epoch 73/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4718 - accuracy: 0.2910 - val_loss: 265.9413 - val_accuracy: 0.2694\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.30496\n",
            "Epoch 74/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.5600 - accuracy: 0.2734 - val_loss: 763.9625 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.30496\n",
            "Epoch 75/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.6625 - accuracy: 0.2480 - val_loss: 1.4542 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.30496\n",
            "Epoch 76/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4872 - accuracy: 0.2650 - val_loss: 1.4555 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.30496\n",
            "Epoch 77/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.5167 - accuracy: 0.2620 - val_loss: 1.4530 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.30496\n",
            "Epoch 78/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4616 - accuracy: 0.2935 - val_loss: 1.4532 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.30496\n",
            "Epoch 79/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4534 - accuracy: 0.2973 - val_loss: 2.0383 - val_accuracy: 0.3006\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.30496\n",
            "Epoch 80/100\n",
            "118/118 [==============================] - 130s 1s/step - loss: 1.4733 - accuracy: 0.2729 - val_loss: 2.9011 - val_accuracy: 0.2694\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.30496\n",
            "Epoch 81/100\n",
            "118/118 [==============================] - 129s 1s/step - loss: 1.4556 - accuracy: 0.2702 - val_loss: 1.4497 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.30496\n",
            "Epoch 82/100\n",
            "118/118 [==============================] - 128s 1s/step - loss: 1.4695 - accuracy: 0.2818 - val_loss: 1.4488 - val_accuracy: 0.3028\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.30496\n",
            "Epoch 83/100\n",
            " 25/118 [=====>........................] - ETA: 1:21 - loss: 1.4361 - accuracy: 0.3005"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-65970891ab99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_validation_batch_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m950\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 callbacks=callbacks_list)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8EEBdxXMPDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eec534b-d858-4d29-e566-69d1b04e30ac"
      },
      "source": [
        "m.save(\"/content/drive/MyDrive/petfinder/weights/my_model\")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/petfinder/weights/my_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qag5KYvwmfE0"
      },
      "source": [
        "# NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wrnGih6nWvL",
        "outputId": "208f4e1a-5ecf-428d-ba08-7c2c182fff73"
      },
      "source": [
        "from nltk.tokenize import TweetTokenizer\r\n",
        "import nltk\r\n",
        "isascii = lambda s: len(s) == len(s.encode())\r\n",
        "tknzr = TweetTokenizer()\r\n",
        "import jieba\r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "ps = PorterStemmer()\r\n",
        "from nltk.stem.lancaster import LancasterStemmer\r\n",
        "lc = LancasterStemmer()\r\n",
        "from nltk.stem import SnowballStemmer\r\n",
        "sb = SnowballStemmer(\"english\")\r\n",
        "nltk.download('averaged_perceptron_tagger')\r\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpq6rWNwpG0n"
      },
      "source": [
        "def custom_tokenizer(text):\r\n",
        "    init_doc = tknzr.tokenize(text)\r\n",
        "    retval = []\r\n",
        "    for t in init_doc:\r\n",
        "        if isascii(t): \r\n",
        "            retval.append(t)\r\n",
        "        else:\r\n",
        "            for w in t:\r\n",
        "                retval.append(w)\r\n",
        "    return retval\r\n",
        "\r\n",
        "def build_emb_matrix(word_dict, emb_dict):\r\n",
        "    embed_size = 300\r\n",
        "    nb_words = len(word_dict)+1000\r\n",
        "    nb_oov = 0\r\n",
        "    embedding_matrix = np.zeros((nb_words, embed_size), dtype=np.float32)\r\n",
        "    unknown_vector = np.zeros((embed_size,), dtype=np.float32) - 1.\r\n",
        "    for key in tqdm(word_dict):\r\n",
        "        word = key\r\n",
        "        embedding_vector = emb_dict.get(word)\r\n",
        "        if embedding_vector is not None:\r\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\r\n",
        "            continue\r\n",
        "        word = key.lower()\r\n",
        "        embedding_vector = emb_dict.get(word)\r\n",
        "        if embedding_vector is not None:\r\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\r\n",
        "            continue\r\n",
        "        word = key.upper()\r\n",
        "        embedding_vector = emb_dict.get(word)\r\n",
        "        if embedding_vector is not None:\r\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\r\n",
        "            continue\r\n",
        "        word = key.capitalize()\r\n",
        "        embedding_vector = emb_dict.get(word)\r\n",
        "        if embedding_vector is not None:\r\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\r\n",
        "            continue\r\n",
        "        word = ps.stem(key)\r\n",
        "        embedding_vector = emb_dict.get(word)\r\n",
        "        if embedding_vector is not None:\r\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\r\n",
        "            continue\r\n",
        "        word = lc.stem(key)\r\n",
        "        embedding_vector = emb_dict.get(word)\r\n",
        "        if embedding_vector is not None:\r\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\r\n",
        "            continue\r\n",
        "        word = sb.stem(key)\r\n",
        "        embedding_vector = emb_dict.get(word)\r\n",
        "        if embedding_vector is not None:\r\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\r\n",
        "            continue\r\n",
        "        nb_oov+=1\r\n",
        "        embedding_matrix[word_dict[key]] = unknown_vector                    \r\n",
        "    return embedding_matrix, nb_words, nb_oov\r\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwhFrV92mhBZ"
      },
      "source": [
        "df['Description'] = df['Description'].fillna(' ')\r\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccAHlICXpM38"
      },
      "source": [
        "english_desc, chinese_desc = [], []\r\n",
        "tokens = set()\r\n",
        "word_dict = {}\r\n",
        "pos_count, word_count = 1, 1 # starts from 1, 0 for padding token\r\n",
        "pos_dict = {}\r\n",
        "eng_sequences = []\r\n",
        "pos_sequences = []\r\n",
        "for i in range(len(df)):\r\n",
        "    e_d, c_d, eng_seq, pos_seq = [], [], [], []\r\n",
        "    doc = custom_tokenizer(df['Description'].iloc[i])\r\n",
        "    for token in doc:\r\n",
        "        if not isascii(token):\r\n",
        "            c_d.append(token)\r\n",
        "        else:\r\n",
        "            e_d.append(token)\r\n",
        "            if token not in word_dict:\r\n",
        "                word_dict[token] = word_count\r\n",
        "                word_count +=1\r\n",
        "    english_desc.append(' '.join(e_d))\r\n",
        "    chinese_desc.append(' '.join(c_d))\r\n",
        "    pos_seq = nltk.pos_tag(e_d)\r\n",
        "    for t in pos_seq:\r\n",
        "        if t[1] not in pos_dict:\r\n",
        "            pos_dict[t[1]] = pos_count\r\n",
        "            pos_count += 1\r\n",
        "    pos_seq = [pos_dict[t[1]] for t in pos_seq]\r\n",
        "    eng_seq = [word_dict[t] for t in e_d]\r\n",
        "    if len(eng_seq)==0:\r\n",
        "        eng_seq.append(0)\r\n",
        "        pos_seq.append(0)\r\n",
        "    eng_sequences.append(eng_seq)\r\n",
        "    pos_sequences.append(pos_seq)\r\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "rnBjp6JZqE_a",
        "outputId": "f9d22552-632f-4674-f05e-3d10f706ee1d"
      },
      "source": [
        "df['English_desc'] = english_desc\r\n",
        "df['Chinese_desc'] = chinese_desc\r\n",
        "\r\n",
        "df['e_description_len'] = df['English_desc'].apply(lambda x:len(x))\r\n",
        "df['e_description_word_len'] = df['English_desc'].apply(lambda x: len(x.split(' ')))\r\n",
        "df['e_description_word_unique'] = df['English_desc'].apply(lambda x: len(set(x.split(' '))))\r\n",
        "\r\n",
        "df['c_description_len'] = df['Chinese_desc'].apply(lambda x:len(x))\r\n",
        "df['c_description_word_len'] = df['Chinese_desc'].apply(lambda x:len(x.split(' ')))\r\n",
        "df['c_description_word_unique'] = df['Chinese_desc'].apply(lambda x: len(set(x)))\r\n",
        "\r\n",
        "df['description_len'] = df['Description'].apply(lambda x:len(x))\r\n",
        "df['description_word_len'] = df['Description'].apply(lambda x: len(x.split(' ')))\r\n",
        "df[df['c_description_len']>0].head()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PetID</th>\n",
              "      <th>PhotoAmt</th>\n",
              "      <th>AdoptionSpeed</th>\n",
              "      <th>Description</th>\n",
              "      <th>English_desc</th>\n",
              "      <th>Chinese_desc</th>\n",
              "      <th>e_description_len</th>\n",
              "      <th>e_description_word_len</th>\n",
              "      <th>e_description_word_unique</th>\n",
              "      <th>c_description_len</th>\n",
              "      <th>c_description_word_len</th>\n",
              "      <th>c_description_word_unique</th>\n",
              "      <th>description_len</th>\n",
              "      <th>description_word_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>c02be41e6</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>Lost Dog Found (Bandar Menjalara, KepongTaman...</td>\n",
              "      <td>Lost Dog Found ( Bandar Menjalara , Kepong Tam...</td>\n",
              "      <td>                       ...</td>\n",
              "      <td>397</td>\n",
              "      <td>78</td>\n",
              "      <td>55</td>\n",
              "      <td>197</td>\n",
              "      <td>99</td>\n",
              "      <td>67</td>\n",
              "      <td>485</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>b0dec8779</td>\n",
              "      <td>21.0</td>\n",
              "      <td>3</td>\n",
              "      <td>~ PLEASE CLICK ON OUR PHOTOS FOR A CLEARER VIE...</td>\n",
              "      <td>~ PLEASE CLICK ON OUR PHOTOS FOR A CLEARER VIE...</td>\n",
              "      <td>   </td>\n",
              "      <td>813</td>\n",
              "      <td>169</td>\n",
              "      <td>116</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>874</td>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>ef14861df</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4</td>\n",
              "      <td>Jasz is a very friendly and well-behaved Schna...</td>\n",
              "      <td>Jasz is a very friendly and well-behaved Schna...</td>\n",
              "      <td> </td>\n",
              "      <td>158</td>\n",
              "      <td>32</td>\n",
              "      <td>27</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>156</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>1e62e6022</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3 month-old male puppy for adoption. a cross b...</td>\n",
              "      <td>3 month-old male puppy for adoption . a cross ...</td>\n",
              "      <td></td>\n",
              "      <td>236</td>\n",
              "      <td>50</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>230</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>2ac4dd8c2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3</td>\n",
              "      <td>Name: Pillo aka Lilo Attitude: Was named Pillo...</td>\n",
              "      <td>Name : Pillo aka Lilo Attitude : Was named Pil...</td>\n",
              "      <td>    </td>\n",
              "      <td>1166</td>\n",
              "      <td>241</td>\n",
              "      <td>156</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1127</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         PetID  PhotoAmt  ...  description_len description_word_len\n",
              "14   c02be41e6       2.0  ...              485                   67\n",
              "64   b0dec8779      21.0  ...              874                  133\n",
              "69   ef14861df       3.0  ...              156                   28\n",
              "72   1e62e6022       5.0  ...              230                   43\n",
              "141  2ac4dd8c2       5.0  ...             1127                  195\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi8ucC8uqqE5",
        "outputId": "7a345c55-a18f-4d3c-907e-c749673a93ed"
      },
      "source": [
        "print(len(eng_sequences))\r\n",
        "print(len(pos_sequences))\r\n",
        "nb_pos = len(pos_dict)\r\n",
        "print(nb_pos)\r\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14652\n",
            "14652\n",
            "45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCuEVwXesVSv",
        "outputId": "f4b54693-aeca-45c7-bac7-3a5981602c0a"
      },
      "source": [
        "import gc\r\n",
        "\r\n",
        "def load_glove():\r\n",
        "    EMBEDDING_FILE = 'glove.840B.300d.txt'\r\n",
        "\r\n",
        "    def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\r\n",
        "\r\n",
        "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in (open(EMBEDDING_FILE)))\r\n",
        "    return embeddings_index\r\n",
        "\r\n",
        "glove_emb = load_glove()\r\n",
        "\r\n",
        "embedding_matrix, nb_words, nb_oov = build_emb_matrix(word_dict, glove_emb)\r\n",
        "print(nb_words, nb_oov)\r\n",
        "del glove_emb\r\n",
        "gc.collect()\r\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 28337/28337 [00:00<00:00, 76142.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "29337 3994\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW68MMvARClU",
        "outputId": "85b11ed6-33e7-4de6-e885-9d60f24e377d"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold,KFold,GroupKFold\r\n",
        "\r\n",
        "n_splits = 5\r\n",
        "# kfold = GroupKFold(n_splits=n_splits)\r\n",
        "split_index = []\r\n",
        "# for train_idx, valid_idx in kfold.split(train, train['AdoptionSpeed'], train['RescuerID']):\r\n",
        "#     split_index.append((train_idx, valid_idx))\r\n",
        "\r\n",
        "kfold = StratifiedKFold(n_splits=n_splits, random_state=1991)\r\n",
        "for train_idx, valid_idx in kfold.split(df, df['AdoptionSpeed']):\r\n",
        "    split_index.append((train_idx, valid_idx))\r\n",
        "print(len(split_index))\r\n",
        "print(split_index)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "[(array([ 2803,  2805,  2806, ..., 14649, 14650, 14651]), array([   0,    1,    2, ..., 3037, 3087, 3098])), (array([    0,     1,     2, ..., 14649, 14650, 14651]), array([2803, 2805, 2806, ..., 5994, 6048, 6076])), (array([    0,     1,     2, ..., 14649, 14650, 14651]), array([5721, 5735, 5737, ..., 8965, 8970, 8971])), (array([    0,     1,     2, ..., 14649, 14650, 14651]), array([ 8222,  8243,  8279, ..., 11895, 11908, 11910])), (array([    0,     1,     2, ..., 11895, 11908, 11910]), array([11382, 11512, 11523, ..., 14649, 14650, 14651]))]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rkt2EDNzckSU",
        "outputId": "476f46d7-4e7e-410a-c294-0d32c2f84f63"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['PetID', 'PhotoAmt', 'AdoptionSpeed', 'Description', 'English_desc',\n",
              "       'Chinese_desc', 'e_description_len', 'e_description_word_len',\n",
              "       'e_description_word_unique', 'c_description_len',\n",
              "       'c_description_word_len', 'c_description_word_unique',\n",
              "       'description_len', 'description_word_len'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N60c2Yqdas4I"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.utils import to_categorical\r\n",
        "import os\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Embedding, Flatten, Dense, GRU\r\n",
        "import matplotlib.pyplot as plt\r\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rth9ON7pcSXt"
      },
      "source": [
        "AdoptionSpeed = df['AdoptionSpeed']\r\n",
        "labels = to_categorical(AdoptionSpeed)\r\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo-ypm1JceGx",
        "outputId": "87d3c834-6ace-4f78-aae0-b9d792a2593a"
      },
      "source": [
        "descriptions = df['English_desc']\r\n",
        "tokenizer = Tokenizer(num_words=1000)\r\n",
        "tokenizer.fit_on_texts(descriptions)\r\n",
        "word_index = tokenizer.word_index\r\n",
        "\r\n",
        "print('Found %s unique tokens' % len(word_index))\r\n",
        "sequences = tokenizer.texts_to_sequences(descriptions)\r\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 19929 unique tokens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1vmTasucx0d",
        "outputId": "d6a40d02-ec45-4964-fa12-4477e7b74b0f"
      },
      "source": [
        "max_len = 100\r\n",
        "max_words = 10000\r\n",
        "training_sample = 10000\r\n",
        "val_sample = 12000\r\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len)\r\n",
        "print(\"Shape of data: \", padded_sequences.shape)\r\n",
        "print(\"Shape of labels: \", labels.shape)\r\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data:  (14652, 100)\n",
            "Shape of labels:  (14652, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdcYGvurc16x"
      },
      "source": [
        "indices = np.arange(df.shape[0])\r\n",
        "np.random.shuffle(indices)\r\n",
        "padded_sequences = padded_sequences[indices]\r\n",
        "labels = labels[indices]\r\n",
        "\r\n",
        "x_train = padded_sequences[:training_sample]\r\n",
        "y_train = labels[:training_sample]\r\n",
        "x_val = padded_sequences[training_sample: val_sample]\r\n",
        "y_val = labels[training_sample: val_sample]\r\n",
        "x_test = padded_sequences[val_sample: ]\r\n",
        "y_test = labels[val_sample: ]\r\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzYNhcCOdeDH",
        "outputId": "2c2eadb4-0d54-4250-df2f-e50f2a12bfcb"
      },
      "source": [
        "embeddings_index = {}\r\n",
        "f = open(\"/content/petfinder/glove.6B.300d.txt\")\r\n",
        "for line in f:\r\n",
        "    values = line.split()\r\n",
        "    word = values[0]\r\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\r\n",
        "    embeddings_index[word] = coefs\r\n",
        "f.close()\r\n",
        "print('Found %s word vectors.' % len(embeddings_index))\r\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gnz-oMdqdOD"
      },
      "source": [
        "embedding_dim = 300\r\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\r\n",
        "for word, i in word_index.items():\r\n",
        "    if i < max_words:\r\n",
        "        embedding_vector = embeddings_index.get(word)\r\n",
        "        if embedding_vector is not None:\r\n",
        "            embedding_matrix[i] = embedding_vector\r\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gdd78hUYdFa_",
        "outputId": "2cb24884-e84e-4ade-cb6e-6a32ab8f54e5"
      },
      "source": [
        "embed_size = 300\r\n",
        "model = Sequential()\r\n",
        "model.add(Embedding(max_words, embed_size, input_length=max_len))\r\n",
        "model.add(GRU(64, return_sequences=True))\r\n",
        "model.add(GRU(64))\r\n",
        "model.add(Dense(5, activation=\"softmax\"))\r\n",
        "model.summary()\r\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 300)          3000000   \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 100, 64)           70272     \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (None, 64)                24960     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 3,095,557\n",
            "Trainable params: 3,095,557\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqe2CddsdUt9",
        "outputId": "93c5cbd1-3d41-4038-e962-17f80bc31fa8"
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29337, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXJq1ymgdGr1"
      },
      "source": [
        "model.layers[0].set_weights([embedding_matrix])\r\n",
        "model.layers[0].trainable = False\r\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gmp5tWgHqitN",
        "outputId": "b19619f4-596e-44c7-fdda-9dcf75017877"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\r\n",
        "history = model.fit(x_train, y_train,\r\n",
        "    epochs=100,\r\n",
        "    batch_size=256,\r\n",
        "    validation_data=(x_val, y_val))\r\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "40/40 [==============================] - 5s 48ms/step - loss: 0.1194 - acc: 0.9520 - val_loss: 5.1762 - val_acc: 0.3275\n",
            "Epoch 2/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.1178 - acc: 0.9521 - val_loss: 5.1833 - val_acc: 0.3375\n",
            "Epoch 3/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.1211 - acc: 0.9520 - val_loss: 5.2163 - val_acc: 0.3325\n",
            "Epoch 4/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.1013 - acc: 0.9552 - val_loss: 5.2412 - val_acc: 0.3445\n",
            "Epoch 5/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.1520 - acc: 0.9436 - val_loss: 5.1753 - val_acc: 0.3415\n",
            "Epoch 6/100\n",
            "40/40 [==============================] - 1s 29ms/step - loss: 0.1487 - acc: 0.9430 - val_loss: 5.1439 - val_acc: 0.3305\n",
            "Epoch 7/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.1553 - acc: 0.9445 - val_loss: 5.1357 - val_acc: 0.3375\n",
            "Epoch 8/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.1149 - acc: 0.9535 - val_loss: 5.1800 - val_acc: 0.3430\n",
            "Epoch 9/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.1196 - acc: 0.9539 - val_loss: 5.1513 - val_acc: 0.3315\n",
            "Epoch 10/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.1251 - acc: 0.9511 - val_loss: 5.1642 - val_acc: 0.3360\n",
            "Epoch 11/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0981 - acc: 0.9557 - val_loss: 5.1908 - val_acc: 0.3390\n",
            "Epoch 12/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.1033 - acc: 0.9548 - val_loss: 5.2674 - val_acc: 0.3385\n",
            "Epoch 13/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0967 - acc: 0.9561 - val_loss: 5.2731 - val_acc: 0.3350\n",
            "Epoch 14/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0948 - acc: 0.9603 - val_loss: 5.2418 - val_acc: 0.3250\n",
            "Epoch 15/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.1009 - acc: 0.9568 - val_loss: 5.2788 - val_acc: 0.3320\n",
            "Epoch 16/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0987 - acc: 0.9558 - val_loss: 5.3542 - val_acc: 0.3300\n",
            "Epoch 17/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0924 - acc: 0.9582 - val_loss: 5.3316 - val_acc: 0.3260\n",
            "Epoch 18/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0982 - acc: 0.9544 - val_loss: 5.3778 - val_acc: 0.3260\n",
            "Epoch 19/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0956 - acc: 0.9545 - val_loss: 5.3845 - val_acc: 0.3315\n",
            "Epoch 20/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0922 - acc: 0.9589 - val_loss: 5.3930 - val_acc: 0.3340\n",
            "Epoch 21/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0903 - acc: 0.9590 - val_loss: 5.4167 - val_acc: 0.3340\n",
            "Epoch 22/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0962 - acc: 0.9568 - val_loss: 5.4215 - val_acc: 0.3355\n",
            "Epoch 23/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0892 - acc: 0.9593 - val_loss: 5.3532 - val_acc: 0.3335\n",
            "Epoch 24/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0937 - acc: 0.9568 - val_loss: 5.4645 - val_acc: 0.3240\n",
            "Epoch 25/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0981 - acc: 0.9545 - val_loss: 5.4127 - val_acc: 0.3340\n",
            "Epoch 26/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.1095 - acc: 0.9525 - val_loss: 5.4272 - val_acc: 0.3370\n",
            "Epoch 27/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.1258 - acc: 0.9441 - val_loss: 5.4071 - val_acc: 0.3265\n",
            "Epoch 28/100\n",
            "40/40 [==============================] - 1s 32ms/step - loss: 0.1317 - acc: 0.9496 - val_loss: 5.3433 - val_acc: 0.3240\n",
            "Epoch 29/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.1076 - acc: 0.9525 - val_loss: 5.3167 - val_acc: 0.3495\n",
            "Epoch 30/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0918 - acc: 0.9591 - val_loss: 5.3785 - val_acc: 0.3360\n",
            "Epoch 31/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.0897 - acc: 0.9592 - val_loss: 5.4083 - val_acc: 0.3365\n",
            "Epoch 32/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0886 - acc: 0.9601 - val_loss: 5.4092 - val_acc: 0.3435\n",
            "Epoch 33/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0945 - acc: 0.9572 - val_loss: 5.4354 - val_acc: 0.3385\n",
            "Epoch 34/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.0965 - acc: 0.9584 - val_loss: 5.4305 - val_acc: 0.3400\n",
            "Epoch 35/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.1146 - acc: 0.9505 - val_loss: 5.4351 - val_acc: 0.3365\n",
            "Epoch 36/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.1169 - acc: 0.9467 - val_loss: 5.4857 - val_acc: 0.3320\n",
            "Epoch 37/100\n",
            "40/40 [==============================] - 1s 29ms/step - loss: 0.1011 - acc: 0.9581 - val_loss: 5.4249 - val_acc: 0.3345\n",
            "Epoch 38/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0938 - acc: 0.9586 - val_loss: 5.5007 - val_acc: 0.3400\n",
            "Epoch 39/100\n",
            "40/40 [==============================] - 1s 26ms/step - loss: 0.0983 - acc: 0.9579 - val_loss: 5.5661 - val_acc: 0.3330\n",
            "Epoch 40/100\n",
            "40/40 [==============================] - 1s 26ms/step - loss: 0.1432 - acc: 0.9410 - val_loss: 5.4307 - val_acc: 0.3275\n",
            "Epoch 41/100\n",
            "40/40 [==============================] - 1s 26ms/step - loss: 0.1953 - acc: 0.9222 - val_loss: 5.3880 - val_acc: 0.3185\n",
            "Epoch 42/100\n",
            "40/40 [==============================] - 1s 26ms/step - loss: 0.1258 - acc: 0.9478 - val_loss: 5.4442 - val_acc: 0.3320\n",
            "Epoch 43/100\n",
            "40/40 [==============================] - 1s 26ms/step - loss: 0.2021 - acc: 0.9281 - val_loss: 5.3328 - val_acc: 0.3405\n",
            "Epoch 44/100\n",
            "40/40 [==============================] - 1s 26ms/step - loss: 0.1175 - acc: 0.9529 - val_loss: 5.4196 - val_acc: 0.3245\n",
            "Epoch 45/100\n",
            "40/40 [==============================] - 1s 26ms/step - loss: 0.1046 - acc: 0.9566 - val_loss: 5.4911 - val_acc: 0.3325\n",
            "Epoch 46/100\n",
            "40/40 [==============================] - 1s 26ms/step - loss: 0.0885 - acc: 0.9561 - val_loss: 5.5253 - val_acc: 0.3365\n",
            "Epoch 47/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0812 - acc: 0.9623 - val_loss: 5.5679 - val_acc: 0.3260\n",
            "Epoch 48/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0869 - acc: 0.9605 - val_loss: 5.5873 - val_acc: 0.3320\n",
            "Epoch 49/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0866 - acc: 0.9603 - val_loss: 5.5765 - val_acc: 0.3265\n",
            "Epoch 50/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0838 - acc: 0.9617 - val_loss: 5.6612 - val_acc: 0.3295\n",
            "Epoch 51/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0869 - acc: 0.9591 - val_loss: 5.6404 - val_acc: 0.3290\n",
            "Epoch 52/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0812 - acc: 0.9620 - val_loss: 5.6747 - val_acc: 0.3245\n",
            "Epoch 53/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0837 - acc: 0.9602 - val_loss: 5.7007 - val_acc: 0.3280\n",
            "Epoch 54/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0815 - acc: 0.9630 - val_loss: 5.7091 - val_acc: 0.3285\n",
            "Epoch 55/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.0799 - acc: 0.9613 - val_loss: 5.7152 - val_acc: 0.3280\n",
            "Epoch 56/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.0817 - acc: 0.9639 - val_loss: 5.6980 - val_acc: 0.3305\n",
            "Epoch 57/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0779 - acc: 0.9609 - val_loss: 5.7113 - val_acc: 0.3345\n",
            "Epoch 58/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.0915 - acc: 0.9577 - val_loss: 5.6936 - val_acc: 0.3265\n",
            "Epoch 59/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0836 - acc: 0.9609 - val_loss: 5.6819 - val_acc: 0.3315\n",
            "Epoch 60/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0772 - acc: 0.9618 - val_loss: 5.7490 - val_acc: 0.3225\n",
            "Epoch 61/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0845 - acc: 0.9582 - val_loss: 5.7400 - val_acc: 0.3315\n",
            "Epoch 62/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0793 - acc: 0.9627 - val_loss: 5.6332 - val_acc: 0.3355\n",
            "Epoch 63/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0802 - acc: 0.9627 - val_loss: 5.7261 - val_acc: 0.3265\n",
            "Epoch 64/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0821 - acc: 0.9591 - val_loss: 5.6669 - val_acc: 0.3310\n",
            "Epoch 65/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0847 - acc: 0.9597 - val_loss: 5.7041 - val_acc: 0.3260\n",
            "Epoch 66/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.0789 - acc: 0.9634 - val_loss: 5.7299 - val_acc: 0.3250\n",
            "Epoch 67/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.0775 - acc: 0.9617 - val_loss: 5.7628 - val_acc: 0.3265\n",
            "Epoch 68/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.0822 - acc: 0.9618 - val_loss: 5.7419 - val_acc: 0.3250\n",
            "Epoch 69/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.0797 - acc: 0.9614 - val_loss: 5.7733 - val_acc: 0.3310\n",
            "Epoch 70/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.0728 - acc: 0.9639 - val_loss: 5.7807 - val_acc: 0.3280\n",
            "Epoch 71/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0746 - acc: 0.9655 - val_loss: 5.7883 - val_acc: 0.3260\n",
            "Epoch 72/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0761 - acc: 0.9597 - val_loss: 5.8320 - val_acc: 0.3265\n",
            "Epoch 73/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.0741 - acc: 0.9634 - val_loss: 5.8108 - val_acc: 0.3260\n",
            "Epoch 74/100\n",
            "40/40 [==============================] - 1s 29ms/step - loss: 0.0907 - acc: 0.9576 - val_loss: 5.7895 - val_acc: 0.3280\n",
            "Epoch 75/100\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.0716 - acc: 0.9662 - val_loss: 5.7928 - val_acc: 0.3275\n",
            "Epoch 76/100\n",
            "40/40 [==============================] - 1s 29ms/step - loss: 0.0736 - acc: 0.9598 - val_loss: 5.8144 - val_acc: 0.3305\n",
            "Epoch 77/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.0745 - acc: 0.9620 - val_loss: 5.8374 - val_acc: 0.3200\n",
            "Epoch 78/100\n",
            "40/40 [==============================] - 1s 29ms/step - loss: 0.0787 - acc: 0.9627 - val_loss: 5.8304 - val_acc: 0.3345\n",
            "Epoch 79/100\n",
            "40/40 [==============================] - 1s 29ms/step - loss: 0.0925 - acc: 0.9591 - val_loss: 5.8111 - val_acc: 0.3405\n",
            "Epoch 80/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.1009 - acc: 0.9545 - val_loss: 5.7321 - val_acc: 0.3380\n",
            "Epoch 81/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.0879 - acc: 0.9586 - val_loss: 5.7610 - val_acc: 0.3170\n",
            "Epoch 82/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0896 - acc: 0.9587 - val_loss: 5.8759 - val_acc: 0.3215\n",
            "Epoch 83/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0892 - acc: 0.9591 - val_loss: 5.9052 - val_acc: 0.3345\n",
            "Epoch 84/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.0751 - acc: 0.9639 - val_loss: 5.9068 - val_acc: 0.3260\n",
            "Epoch 85/100\n",
            "40/40 [==============================] - 1s 27ms/step - loss: 0.0756 - acc: 0.9619 - val_loss: 5.8596 - val_acc: 0.3320\n",
            "Epoch 86/100\n",
            "40/40 [==============================] - 1s 29ms/step - loss: 0.0798 - acc: 0.9601 - val_loss: 5.9200 - val_acc: 0.3235\n",
            "Epoch 87/100\n",
            "40/40 [==============================] - 1s 29ms/step - loss: 0.0826 - acc: 0.9600 - val_loss: 5.8601 - val_acc: 0.3235\n",
            "Epoch 88/100\n",
            "40/40 [==============================] - 1s 29ms/step - loss: 0.0785 - acc: 0.9632 - val_loss: 5.9351 - val_acc: 0.3280\n",
            "Epoch 89/100\n",
            "40/40 [==============================] - 1s 30ms/step - loss: 0.1075 - acc: 0.9513 - val_loss: 5.6547 - val_acc: 0.3385\n",
            "Epoch 90/100\n",
            "40/40 [==============================] - 1s 29ms/step - loss: 0.1154 - acc: 0.9522 - val_loss: 5.8038 - val_acc: 0.3415\n",
            "Epoch 91/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.1282 - acc: 0.9449 - val_loss: 5.8037 - val_acc: 0.3195\n",
            "Epoch 92/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.1106 - acc: 0.9521 - val_loss: 5.7180 - val_acc: 0.3220\n",
            "Epoch 93/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.0895 - acc: 0.9595 - val_loss: 5.7341 - val_acc: 0.3220\n",
            "Epoch 94/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.0860 - acc: 0.9597 - val_loss: 5.8689 - val_acc: 0.3320\n",
            "Epoch 95/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.0830 - acc: 0.9590 - val_loss: 5.8378 - val_acc: 0.3365\n",
            "Epoch 96/100\n",
            "40/40 [==============================] - 1s 29ms/step - loss: 0.0774 - acc: 0.9655 - val_loss: 5.8712 - val_acc: 0.3265\n",
            "Epoch 97/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.0744 - acc: 0.9642 - val_loss: 5.8964 - val_acc: 0.3275\n",
            "Epoch 98/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.0741 - acc: 0.9638 - val_loss: 5.9481 - val_acc: 0.3295\n",
            "Epoch 99/100\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.0823 - acc: 0.9594 - val_loss: 5.9244 - val_acc: 0.3260\n",
            "Epoch 100/100\n",
            "40/40 [==============================] - 1s 29ms/step - loss: 0.0724 - acc: 0.9644 - val_loss: 5.9144 - val_acc: 0.3265\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "JnRusRw8rJib",
        "outputId": "d38e117a-38fd-439e-92b9-335fcd13876e"
      },
      "source": [
        "acc = history.history['acc']\r\n",
        "val_acc = history.history['val_acc']\r\n",
        "loss = history.history['loss']\r\n",
        "val_loss = history.history['val_loss']\r\n",
        "epochs = range(1, len(acc) + 1)\r\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\r\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\r\n",
        "plt.title('Training and validation accuracy')\r\n",
        "plt.legend()\r\n",
        "plt.figure()\r\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\r\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\r\n",
        "plt.title('Training and validation loss')\r\n",
        "plt.legend()\r\n",
        "plt.show()\r\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}